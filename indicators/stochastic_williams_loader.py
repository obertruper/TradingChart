#!/usr/bin/env python3
"""
Stochastic Oscillator & Williams %R Loader with Multi-Timeframe Support
=======================================================================
–ó–∞–≥—Ä—É–∑—á–∏–∫ Stochastic –∏ Williams %R –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π:
- –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π Stochastic (scalping, intraday, fast, classic, swing, fibonacci_swing, position, fibonacci_long)
- –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø–µ—Ä–∏–æ–¥–æ–≤ Williams %R (6, 10, 14, 20, 30)
- –ë–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å checkpoint
- –õ—é–±—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ (1m, 15m, 1h)
- –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π
- Multi-symbol support

Stochastic Oscillator:
- %K = (Close - Low_N) / (High_N - Low_N) √ó 100
- %K_smooth = SMA(%K, k_smooth)
- %D = SMA(%K_smooth, d_period)

Williams %R:
- %R = -((High_N - Close) / (High_N - Low_N)) √ó 100
- –î–∏–∞–ø–∞–∑–æ–Ω: –æ—Ç -100 –¥–æ 0
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta, timezone
import psycopg2
import psycopg2.extras
from typing import Dict, List, Tuple, Optional
import logging
from tqdm import tqdm
import sys
import os
import warnings
import yaml
import argparse
import time

# –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è pandas
warnings.filterwarnings('ignore', message='pandas only supports SQLAlchemy')

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from indicators.database import DatabaseConnection

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
def setup_logging():
    """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –∫–æ–Ω—Å–æ–ª—å –∏ —Ñ–∞–π–ª"""
    log_dir = os.path.join(os.path.dirname(__file__), 'logs')
    os.makedirs(log_dir, exist_ok=True)

    log_filename = os.path.join(log_dir, f'stochastic_williams_loader_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log')

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler(log_filename, encoding='utf-8')
        ]
    )

    logger = logging.getLogger(__name__)
    logger.info(f"üìù –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ. –õ–æ–≥-—Ñ–∞–π–ª: {log_filename}")

    return logger

logger = setup_logging()


class StochasticLoader:
    """–ó–∞–≥—Ä—É–∑—á–∏–∫ Stochastic Oscillator –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤"""

    def __init__(self, symbol: str = 'BTCUSDT', force_reload: bool = False, check_nulls: bool = False):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≥—Ä—É–∑—á–∏–∫–∞

        Args:
            symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞
            force_reload: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø–µ—Ä–µ—Å—á–µ—Ç –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö —Å –Ω–∞—á–∞–ª–∞ –∏—Å—Ç–æ—Ä–∏–∏
            check_nulls: –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏ –∑–∞–ø–æ–ª–Ω–∏—Ç—å NULL –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ –¥–∞–Ω–Ω—ã—Ö
        """
        self.db = DatabaseConnection()
        self.symbol = symbol
        self.force_reload = force_reload
        self.check_nulls = check_nulls
        self.symbol_progress = ""  # –î–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø—Ä–∏ multi-symbol
        self.config = self.load_config()

        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –º–∞–ø–∏–Ω–≥ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ –Ω–∞ –º–∏–Ω—É—Ç—ã
        self.timeframe_minutes = self._parse_timeframes()

    def _parse_timeframes(self) -> dict:
        """
        –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –ø–∞—Ä—Å–∏—Ç —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ñ–æ—Ä–º–∞—Ç—ã: 1m, 5m, 15m, 30m, 1h, 4h, 1d, 1w

        Returns:
            dict: –ú–∞–ø–∏–Ω–≥ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–∏–Ω—É—Ç
        """
        timeframe_map = {}

        # –ü–æ–ª—É—á–∞–µ–º —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ
        timeframes = self.config.get('timeframes', ['1m', '15m', '1h'])

        for tf in timeframes:
            # –ü–∞—Ä—Å–∏–º —á–∏—Å–ª–æ –∏ –µ–¥–∏–Ω–∏—Ü—É –∏–∑–º–µ—Ä–µ–Ω–∏—è
            import re
            match = re.match(r'^(\d+)([mhdw])$', tf.lower())

            if not match:
                logger.warning(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∞–π–º—Ñ—Ä–µ–π–º: {tf}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue

            value = int(match.group(1))
            unit = match.group(2)

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –º–∏–Ω—É—Ç—ã
            if unit == 'm':
                minutes = value
            elif unit == 'h':
                minutes = value * 60
            elif unit == 'd':
                minutes = value * 60 * 24
            elif unit == 'w':
                minutes = value * 60 * 24 * 7
            else:
                logger.warning(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–∞—è –µ–¥–∏–Ω–∏—Ü–∞ –≤—Ä–µ–º–µ–Ω–∏: {unit}")
                continue

            timeframe_map[tf] = minutes

        logger.info(f"–†–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã: {timeframe_map}")
        return timeframe_map

    def load_config(self) -> dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ YAML —Ñ–∞–π–ª–∞"""
        config_path = os.path.join(os.path.dirname(__file__), 'indicators_config.yaml')

        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)

        return config

    def get_table_name(self, timeframe: str) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–º—è —Ç–∞–±–ª–∏—Ü—ã –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞"""
        return f"indicators_bybit_futures_{timeframe}"

    def calculate_stochastic(self, df: pd.DataFrame, k_period: int,
                            k_smooth: int, d_period: int) -> Tuple[pd.Series, pd.Series]:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç Stochastic Oscillator (%K –∏ %D)

        –§–æ—Ä–º—É–ª–∞:
        1. %K_raw = (Close - Low_N) / (High_N - Low_N) √ó 100
        2. %K = SMA(%K_raw, k_smooth) –µ—Å–ª–∏ k_smooth > 1, –∏–Ω–∞—á–µ %K = %K_raw
        3. %D = SMA(%K, d_period)

        Args:
            df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ high, low, close
            k_period: –ü–µ—Ä–∏–æ–¥ –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ High/Low –¥–∏–∞–ø–∞–∑–æ–Ω–∞
            k_smooth: –ü–µ—Ä–∏–æ–¥ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è %K (1 = –±–µ–∑ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è)
            d_period: –ü–µ—Ä–∏–æ–¥ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è %D (—Å–∏–≥–Ω–∞–ª—å–Ω–∞—è –ª–∏–Ω–∏—è)

        Returns:
            Tuple[k_values, d_values]: %K –∏ %D –∑–Ω–∞—á–µ–Ω–∏—è
        """
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º rolling high –∏ low
        rolling_high = df['high'].rolling(window=k_period).max()
        rolling_low = df['low'].rolling(window=k_period).min()

        # %K raw (fast stochastic)
        # –ò–∑–±–µ–≥–∞–µ–º –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å
        denominator = rolling_high - rolling_low
        k_raw = np.where(
            denominator != 0,
            ((df['close'] - rolling_low) / denominator) * 100,
            np.nan
        )
        k_raw = pd.Series(k_raw, index=df.index)

        # %K smoothed (slow stochastic)
        if k_smooth > 1:
            k = k_raw.rolling(window=k_smooth).mean()
        else:
            k = k_raw

        # %D (signal line)
        d = k.rolling(window=d_period).mean()

        return k, d

    def ensure_stochastic_columns(self, timeframe: str, configs: List[Dict]):
        """
        –°–æ–∑–¥–∞–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è Stochastic –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç

        Args:
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º (1m, 15m, 1h)
            configs: –°–ø–∏—Å–æ–∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π Stochastic
        """
        table_name = self.get_table_name(timeframe)

        with self.db.get_connection() as conn:
            cur = conn.cursor()

            try:
                for config in configs:
                    k_period = config['k_period']
                    k_smooth = config['k_smooth']
                    d_period = config['d_period']

                    # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º–µ–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫ (—Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã)
                    base_name = f"stoch_{k_period}_{k_smooth}_{d_period}"
                    columns = [
                        f"{base_name}_k",
                        f"{base_name}_d"
                    ]

                    for col_name in columns:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏
                        cur.execute("""
                            SELECT EXISTS (
                                SELECT 1 FROM information_schema.columns
                                WHERE table_schema = 'public'
                                AND table_name = %s
                                AND column_name = %s
                            );
                        """, (table_name, col_name))

                        exists = cur.fetchone()[0]

                        if not exists:
                            logger.info(f"‚ûï –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ {col_name} –≤ —Ç–∞–±–ª–∏—Ü–µ {table_name}")
                            cur.execute(f"""
                                ALTER TABLE {table_name}
                                ADD COLUMN {col_name} DECIMAL(10,4);
                            """)
                            logger.info(f"‚úÖ –ö–æ–ª–æ–Ω–∫–∞ {col_name} —Å–æ–∑–¥–∞–Ω–∞")

                conn.commit()

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∫–æ–ª–æ–Ω–æ–∫: {e}")
                conn.rollback()
                raise
            finally:
                cur.close()

    def get_data_range(self, timeframe: str) -> Tuple[datetime, datetime]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –¥–∏–∞–ø–∞–∑–æ–Ω –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–∑–æ–≤–æ–π —Ç–∞–±–ª–∏—Ü–µ —Å–≤–µ—á–µ–π
        –í—Å–µ–≥–¥–∞ —á–∏—Ç–∞–µ—Ç –∏–∑ candles_bybit_futures_1m

        Returns:
            (min_date, max_date)
        """
        with self.db.get_connection() as conn:
            cur = conn.cursor()

            try:
                cur.execute("""
                    SELECT MIN(timestamp), MAX(timestamp)
                    FROM candles_bybit_futures_1m
                    WHERE symbol = %s
                """, (self.symbol,))

                result = cur.fetchone()

                if not result or result[0] is None:
                    raise ValueError(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {self.symbol} –≤ candles_bybit_futures_1m")

                return result[0], result[1]
            finally:
                cur.close()

    def get_last_stochastic_date(self, timeframe: str, config: Dict) -> Optional[datetime]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω—é—é –¥–∞—Ç—É —Å —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–º Stochastic –¥–ª—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

        Args:
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Stochastic

        Returns:
            –ü–æ—Å–ª–µ–¥–Ω—è—è –¥–∞—Ç–∞ –∏–ª–∏ None
        """
        table_name = self.get_table_name(timeframe)

        k_period = config['k_period']
        k_smooth = config['k_smooth']
        d_period = config['d_period']
        col_name = f"stoch_{k_period}_{k_smooth}_{d_period}_k"

        with self.db.get_connection() as conn:
            cur = conn.cursor()

            try:
                cur.execute(f"""
                    SELECT MAX(timestamp)
                    FROM {table_name}
                    WHERE symbol = %s AND {col_name} IS NOT NULL
                """, (self.symbol,))

                result = cur.fetchone()
                return result[0] if result[0] else None
            finally:
                cur.close()

    def get_null_timestamps_for_config(self, timeframe: str, config: Dict) -> set:
        """
        –ù–∞—Ö–æ–¥–∏—Ç timestamps —Å NULL –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ Stochastic.
        –ò—Å–∫–ª—é—á–∞–µ—Ç –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ NULL –≤ –Ω–∞—á–∞–ª–µ –¥–∞–Ω–Ω—ã—Ö (–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ lookback).

        Args:
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Stochastic

        Returns:
            set: –ú–Ω–æ–∂–µ—Å—Ç–≤–æ timestamps —Å NULL
        """
        table_name = self.get_table_name(timeframe)
        k_period = config['k_period']
        k_smooth = config['k_smooth']
        d_period = config['d_period']
        base_name = f"stoch_{k_period}_{k_smooth}_{d_period}"
        col_k = f"{base_name}_k"
        col_d = f"{base_name}_d"

        # Natural boundary: k_period + k_smooth + d_period - 2 periods
        max_lookback = k_period + k_smooth + d_period - 2
        minutes = self.timeframe_minutes[timeframe]

        with self.db.get_connection() as conn:
            cur = conn.cursor()
            try:
                cur.execute(f"""
                    SELECT MIN(timestamp) FROM {table_name}
                    WHERE symbol = %s
                """, (self.symbol,))
                min_date = cur.fetchone()[0]
                if not min_date:
                    return set()

                boundary = min_date + timedelta(minutes=max_lookback * minutes)

                cur.execute(f"""
                    SELECT timestamp FROM {table_name}
                    WHERE symbol = %s
                      AND timestamp >= %s
                      AND ({col_k} IS NULL OR {col_d} IS NULL)
                """, (self.symbol, boundary))

                return {row[0] for row in cur.fetchall()}
            finally:
                cur.close()

    def get_last_complete_period(self, current_time: datetime, timeframe: str) -> datetime:
        """
        –ü–æ–ª—É—á–∞–µ—Ç timestamp –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ó–ê–í–ï–†–®–ï–ù–ù–û–ì–û –ø–µ—Ä–∏–æ–¥–∞

        Args:
            current_time: –¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è (timezone-aware)
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º

        Returns:
            Timestamp –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞
        """
        minutes = self.timeframe_minutes[timeframe]

        if timeframe == '1m':
            return current_time.replace(second=0, microsecond=0) - timedelta(minutes=1)

        elif timeframe == '15m':
            minute = (current_time.minute // 15) * 15
            result = current_time.replace(minute=minute, second=0, microsecond=0)

            if current_time.minute % 15 == 0 and current_time.second == 0:
                result -= timedelta(minutes=15)

            return result

        elif timeframe == '1h':
            result = current_time.replace(minute=0, second=0, microsecond=0)

            if current_time.minute == 0 and current_time.second == 0:
                result -= timedelta(hours=1)

            return result

        elif timeframe == '4h':
            hour_block = (current_time.hour // 4) * 4
            result = current_time.replace(hour=hour_block, minute=0, second=0, microsecond=0)
            if current_time.hour % 4 == 0 and current_time.minute == 0 and current_time.second == 0:
                result -= timedelta(hours=4)
            return result

        elif timeframe == '1d':
            return (current_time - timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)

        else:
            total_minutes = int(current_time.timestamp() / 60)
            period_start_minutes = (total_minutes // minutes) * minutes
            result = datetime.fromtimestamp(period_start_minutes * 60)

            if total_minutes % minutes == 0:
                result -= timedelta(minutes=minutes)

            return result

    def aggregate_candles(self, start_date: datetime, end_date: datetime, timeframe: str) -> pd.DataFrame:
        """
        –ê–≥—Ä–µ–≥–∏—Ä—É–µ—Ç –º–∏–Ω—É—Ç–Ω—ã–µ —Å–≤–µ—á–∏ –≤ –Ω—É–∂–Ω—ã–π —Ç–∞–π–º—Ñ—Ä–µ–π–º –∏–ª–∏ —á–∏—Ç–∞–µ—Ç –Ω–∞–ø—Ä—è–º—É—é

        Args:
            start_date: –ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞
            end_date: –ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞
            timeframe: –¶–µ–ª–µ–≤–æ–π —Ç–∞–π–º—Ñ—Ä–µ–π–º

        Returns:
            DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏: timestamp, symbol, high, low, close
        """
        with self.db.get_connection() as conn:
            if timeframe == '1m':
                # –î–ª—è –º–∏–Ω—É—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —á–∏—Ç–∞–µ–º –Ω–∞–ø—Ä—è–º—É—é
                query = """
                    SELECT timestamp, symbol, high, low, close
                    FROM candles_bybit_futures_1m
                    WHERE symbol = %s
                      AND timestamp >= %s
                      AND timestamp <= %s
                    ORDER BY timestamp
                """
                df = pd.read_sql_query(query, conn, params=(self.symbol, start_date, end_date))
            else:
                # –î–ª—è —Å—Ç–∞—Ä—à–∏—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ –∞–≥—Ä–µ–≥–∏—Ä—É–µ–º –∏–∑ –º–∏–Ω—É—Ç–Ω—ã—Ö
                minutes = self.timeframe_minutes[timeframe]

                # –í–ê–ñ–ù–û: Timestamp = –ù–ê–ß–ê–õ–û –ø–µ—Ä–∏–æ–¥–∞ (Bybit standard)
                if timeframe == '1d':
                    query = """
                        WITH time_groups AS (
                            SELECT
                                timestamp,
                                date_trunc('day', timestamp) as period_start,
                                high, low, close,
                                symbol
                            FROM candles_bybit_futures_1m
                            WHERE symbol = %s
                              AND timestamp >= %s
                              AND timestamp <= %s
                        )
                        SELECT
                            period_start as timestamp,
                            symbol,
                            MAX(high) as high,
                            MIN(low) as low,
                            (ARRAY_AGG(close ORDER BY timestamp DESC))[1] as close
                        FROM time_groups
                        GROUP BY period_start, symbol
                        ORDER BY period_start
                    """
                elif timeframe == '4h':
                    query = """
                        WITH time_groups AS (
                            SELECT
                                timestamp,
                                date_trunc('day', timestamp) +
                                INTERVAL '4 hours' * (EXTRACT(HOUR FROM timestamp)::integer / 4) as period_start,
                                high, low, close,
                                symbol
                            FROM candles_bybit_futures_1m
                            WHERE symbol = %s
                              AND timestamp >= %s
                              AND timestamp <= %s
                        )
                        SELECT
                            period_start as timestamp,
                            symbol,
                            MAX(high) as high,
                            MIN(low) as low,
                            (ARRAY_AGG(close ORDER BY timestamp DESC))[1] as close
                        FROM time_groups
                        GROUP BY period_start, symbol
                        ORDER BY period_start
                    """
                else:
                    query = f"""
                        WITH time_groups AS (
                            SELECT
                                timestamp,
                                DATE_TRUNC('hour', timestamp) +
                                INTERVAL '1 minute' * (FLOOR(EXTRACT(MINUTE FROM timestamp) / {minutes}) * {minutes}) as period_start,
                                high, low, close,
                                symbol
                            FROM candles_bybit_futures_1m
                            WHERE symbol = %s
                              AND timestamp >= %s
                              AND timestamp <= %s
                        )
                        SELECT
                            period_start as timestamp,
                            symbol,
                            MAX(high) as high,
                            MIN(low) as low,
                            (ARRAY_AGG(close ORDER BY timestamp DESC))[1] as close
                        FROM time_groups
                        GROUP BY period_start, symbol
                        ORDER BY period_start
                    """

                df = pd.read_sql_query(query, conn, params=(self.symbol, start_date, end_date))

            return df

    def save_stochastic_to_db(self, df: pd.DataFrame, table_name: str, config: Dict):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç Stochastic –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö

        Args:
            df: DataFrame —Å Stochastic –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
            table_name: –ò–º—è —Ç–∞–±–ª–∏—Ü—ã
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Stochastic
        """
        k_period = config['k_period']
        k_smooth = config['k_smooth']
        d_period = config['d_period']

        base_name = f"stoch_{k_period}_{k_smooth}_{d_period}"
        col_k = f"{base_name}_k"
        col_d = f"{base_name}_d"

        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏ —Å –Ω–µ-NULL –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        df_to_save = df[df[col_k].notna()].copy()

        if len(df_to_save) == 0:
            return

        with self.db.get_connection() as conn:
            cur = conn.cursor()

            try:
                update_query = f"""
                    UPDATE {table_name}
                    SET {col_k} = %s,
                        {col_d} = %s
                    WHERE timestamp = %s AND symbol = %s
                """

                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è batch update
                data = [
                    (
                        float(row[col_k]) if pd.notna(row[col_k]) else None,
                        float(row[col_d]) if pd.notna(row[col_d]) else None,
                        row['timestamp'],
                        row['symbol']
                    )
                    for _, row in df_to_save.iterrows()
                ]

                # –í—ã–ø–æ–ª–Ω—è–µ–º batch update
                psycopg2.extras.execute_batch(cur, update_query, data, page_size=1000)
                conn.commit()

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ Stochastic {config['name']}: {e}")
                conn.rollback()
                raise
            finally:
                cur.close()

    def calculate_and_save_stochastic(self, timeframe: str, configs: List[Dict], batch_days: int = 1):
        """
        –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç Stochastic –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

        Args:
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º (1m, 15m, 1h)
            configs: –°–ø–∏—Å–æ–∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π Stochastic
            batch_days: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –≤ –¥–Ω—è—Ö
        """
        table_name = self.get_table_name(timeframe)

        logger.info(f"üöÄ –ù–∞—á–∞–ª–æ —Ä–∞—Å—á–µ—Ç–∞ Stochastic –¥–ª—è {self.symbol} –Ω–∞ —Ç–∞–π–º—Ñ—Ä–µ–π–º–µ {timeframe}")
        logger.info(f"üìä –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {[c['name'] for c in configs]}")
        logger.info(f"üì¶ –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {batch_days} –¥–Ω–µ–π")

        # –ü–æ–ª—É—á–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        min_date, max_date = self.get_data_range(timeframe)
        logger.info(f"üìÖ –î–∏–∞–ø–∞–∑–æ–Ω –¥–∞–Ω–Ω—ã—Ö –≤ –ë–î: {min_date} - {max_date}")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥
        last_complete_period = self.get_last_complete_period(max_date, timeframe)

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º max_date –ø–æ—Å–ª–µ–¥–Ω–∏–º –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–º –ø–µ—Ä–∏–æ–¥–æ–º
        if max_date > last_complete_period:
            logger.info(f"‚è∏Ô∏è  –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ max_date –¥–æ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞: {last_complete_period}")
            max_date = last_complete_period

        # –ü–æ–ª—É—á–∞–µ–º lookback multiplier –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        lookback_multiplier = self.config['indicators']['stochastic'].get('lookback_multiplier', 2)

        # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        for config in configs:
            logger.info(f"\n{'='*80}")
            logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {config['name']} ({config['k_period']}, {config['k_smooth']}, {config['d_period']})")
            logger.info(f"{'='*80}")

            null_timestamps = None  # None = –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –≤—Å—ë, set() = —Ç–æ–ª—å–∫–æ NULL timestamps

            # –ï—Å–ª–∏ force_reload - –≤—Å–µ–≥–¥–∞ –Ω–∞—á–∏–Ω–∞–µ–º —Å –Ω–∞—á–∞–ª–∞
            if self.force_reload:
                start_date = min_date
                logger.info(f"üîÑ Stochastic {config['name']}: FORCE RELOAD - –ø–µ—Ä–µ—Å—á–µ—Ç —Å –Ω–∞—á–∞–ª–∞ –∏—Å—Ç–æ—Ä–∏–∏")
            elif self.check_nulls:
                null_ts = self.get_null_timestamps_for_config(timeframe, config)
                if not null_ts:
                    logger.info(f"  ‚úÖ Stochastic {config['name']}: –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                    continue
                null_timestamps = null_ts
                logger.info(f"üîç Stochastic {config['name']}: –Ω–∞–π–¥–µ–Ω–æ {len(null_ts)} NULL –∑–∞–ø–∏—Å–µ–π")
                start_date = min(null_ts).replace(hour=0, minute=0, second=0, microsecond=0)
            else:
                # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω—é—é –¥–∞—Ç—É —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è —ç—Ç–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
                last_date = self.get_last_stochastic_date(timeframe, config)

                if last_date:
                    start_date = last_date + timedelta(days=1)
                    start_date = start_date.replace(hour=0, minute=0, second=0, microsecond=0)
                    logger.info(f"üìÖ –ü–æ—Å–ª–µ–¥–Ω—è—è –¥–∞—Ç–∞ Stochastic {config['name']}: {last_date}")
                    logger.info(f"‚ñ∂Ô∏è  –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å: {start_date}")
                else:
                    start_date = min_date
                    logger.info(f"üÜï Stochastic {config['name']} –ø—É—Å—Ç, –Ω–∞—á–∏–Ω–∞–µ–º —Å –Ω–∞—á–∞–ª–∞: {start_date}")

            # –ï—Å–ª–∏ —É–∂–µ –≤—Å–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ
            if start_date > max_date:
                logger.info(f"‚úÖ Stochastic {config['name']} —É–∂–µ –∞–∫—Ç—É–∞–ª–µ–Ω (–¥–æ {max_date})")
                continue

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            total_days = (max_date.date() - start_date.date()).days + 1
            logger.info(f"üìÜ –í—Å–µ–≥–æ –¥–Ω–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {total_days}")

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á–∞–º–∏
            current_date = start_date
            processed_days = 0
            total_records = 0

            # Lookback –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Ä–∞—Å—á–µ—Ç–∞
            max_period = max(config['k_period'], config['k_smooth'], config['d_period'])
            lookback_periods = max_period * lookback_multiplier
            lookback_minutes = lookback_periods * self.timeframe_minutes[timeframe]
            lookback_delta = timedelta(minutes=lookback_minutes)

            logger.info(f"üîô Lookback –ø–µ—Ä–∏–æ–¥: {lookback_minutes} –º–∏–Ω—É—Ç ({lookback_periods} –ø–µ—Ä–∏–æ–¥–æ–≤ √ó {self.timeframe_minutes[timeframe]} –º–∏–Ω)")

            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
            config_names = [f"{c['k_period']}_{c['k_smooth']}_{c['d_period']}" for c in configs]
            config_list_str = ','.join(config_names)

            with tqdm(total=total_days,
                     desc=f"{self.symbol} {self.symbol_progress} STOCH[{config_list_str}] {timeframe.upper()}",
                     unit="day",
                     bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}] {postfix}') as pbar:
                while current_date <= max_date:
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω–µ—Ü –±–∞—Ç—á–∞
                    batch_end = min(
                        current_date + timedelta(days=batch_days) - timedelta(seconds=1),
                        max_date
                    )

                    # –î–æ–±–∞–≤–ª—è–µ–º lookback –∫ –Ω–∞—á–∞–ª—É –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Ä–∞—Å—á–µ—Ç–∞
                    data_start = current_date - lookback_delta

                    try:
                        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å lookback
                        df = self.aggregate_candles(data_start, batch_end, timeframe)

                        if len(df) == 0:
                            current_date += timedelta(days=batch_days)
                            processed_days += batch_days
                            pbar.update(min(batch_days, total_days - processed_days + batch_days))
                            continue

                        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º Stochastic
                        k_values, d_values = self.calculate_stochastic(
                            df,
                            config['k_period'],
                            config['k_smooth'],
                            config['d_period']
                        )

                        # –î–æ–±–∞–≤–ª—è–µ–º –∫ DataFrame
                        base_name = f"stoch_{config['k_period']}_{config['k_smooth']}_{config['d_period']}"
                        df[f'{base_name}_k'] = k_values
                        df[f'{base_name}_d'] = d_values

                        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ü–µ–ª–µ–≤–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω (–±–µ–∑ lookback)
                        df_to_save = df[df['timestamp'] >= current_date].copy()

                        # –í —Ä–µ–∂–∏–º–µ check_nulls –∑–∞–ø–∏—Å—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ NULL timestamps
                        if null_timestamps is not None and not df_to_save.empty:
                            df_to_save = df_to_save[df_to_save['timestamp'].isin(null_timestamps)]

                        if df_to_save.empty:
                            current_date += timedelta(days=batch_days)
                            processed_days += batch_days
                            pbar.update(min(batch_days, total_days - processed_days + batch_days))
                            continue

                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å retry –ª–æ–≥–∏–∫–æ–π
                        max_retries = 3
                        for attempt in range(max_retries):
                            try:
                                self.save_stochastic_to_db(df_to_save, table_name, config)
                                break
                            except Exception as e:
                                if attempt < max_retries - 1:
                                    wait_time = 2 ** attempt
                                    time.sleep(wait_time)
                                else:
                                    logger.error(f"‚ùå –í—Å–µ {max_retries} –ø–æ–ø—ã—Ç–∫–∏ –Ω–µ —É–¥–∞–ª–∏—Å—å –¥–ª—è –±–∞—Ç—á–∞ {current_date.date()}")
                                    raise

                        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                        days_in_batch = min(batch_days, (max_date.date() - current_date.date()).days + 1)
                        processed_days += days_in_batch
                        total_records += len(df_to_save)
                        pbar.update(days_in_batch)

                        # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ progress bar
                        if not df_to_save.empty:
                            latest_timestamp = df_to_save['timestamp'].max()
                            pbar.set_postfix({
                                '–≤—Å–µ–≥–æ': f'{total_records:,}',
                                '–ø–æ—Å–ª–µ–¥–Ω—è—è': latest_timestamp.strftime('%Y-%m-%d %H:%M')
                            })

                    except Exception as e:
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –±–∞—Ç—á–∞ {current_date.date()}: {e}")
                        raise

                    # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –±–∞—Ç—á—É
                    current_date += timedelta(days=batch_days)

            logger.info(f"‚úÖ Stochastic {config['name']} –∑–∞–≤–µ—Ä—à–µ–Ω: {total_records:,} –∑–∞–ø–∏—Å–µ–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞ {processed_days} –¥–Ω–µ–π")

        logger.info(f"\n{'='*80}")
        logger.info(f"üéâ –í—Å–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ Stochastic –¥–ª—è {timeframe} –∑–∞–≤–µ—Ä—à–µ–Ω—ã!")
        logger.info(f"{'='*80}")

    def run(self, timeframe: str = None, batch_days: int = None):
        """
        –ó–∞–ø—É—Å–∫ –∑–∞–≥—Ä—É–∑–∫–∏ Stochastic

        Args:
            timeframe: –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ç–∞–π–º—Ñ—Ä–µ–π–º –∏–ª–∏ None –¥–ª—è –≤—Å–µ—Ö
            batch_days: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –≤ –¥–Ω—è—Ö
        """
        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        stochastic_config = self.config['indicators']['stochastic']
        configs = stochastic_config['configurations']

        if batch_days is None:
            batch_days = stochastic_config.get('batch_days', 1)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if timeframe:
            timeframes = [timeframe]
        else:
            timeframes = self.config.get('timeframes', ['1m', '15m', '1h'])

        logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ Stochastic Loader –¥–ª—è {self.symbol}")
        logger.info(f"‚è∞ –¢–∞–π–º—Ñ—Ä–µ–π–º—ã: {timeframes}")
        logger.info(f"üìä –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {[c['name'] for c in configs]}")
        logger.info(f"üì¶ Batch size: {batch_days} –¥–Ω–µ–π")

        for tf in timeframes:
            logger.info(f"\n{'#'*80}")
            logger.info(f"‚è∞ –¢–∞–π–º—Ñ—Ä–µ–π–º: {tf}")
            logger.info(f"{'#'*80}")

            # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            self.ensure_stochastic_columns(tf, configs)

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º Stochastic
            self.calculate_and_save_stochastic(tf, configs, batch_days)

        logger.info(f"\n{'#'*80}")
        logger.info(f"üéâ –ó–∞–≥—Ä—É–∑–∫–∞ Stochastic –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –≤—Å–µ—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤!")
        logger.info(f"{'#'*80}")


class WilliamsRLoader:
    """–ó–∞–≥—Ä—É–∑—á–∏–∫ Williams %R –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤"""

    def __init__(self, symbol: str = 'BTCUSDT', force_reload: bool = False, check_nulls: bool = False):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≥—Ä—É–∑—á–∏–∫–∞

        Args:
            symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞
            force_reload: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø–µ—Ä–µ—Å—á–µ—Ç –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö —Å –Ω–∞—á–∞–ª–∞ –∏—Å—Ç–æ—Ä–∏–∏
            check_nulls: –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏ –∑–∞–ø–æ–ª–Ω–∏—Ç—å NULL –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ –¥–∞–Ω–Ω—ã—Ö
        """
        self.db = DatabaseConnection()
        self.symbol = symbol
        self.force_reload = force_reload
        self.check_nulls = check_nulls
        self.symbol_progress = ""  # –î–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø—Ä–∏ multi-symbol
        self.config = self.load_config()

        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –º–∞–ø–∏–Ω–≥ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ –Ω–∞ –º–∏–Ω—É—Ç—ã
        self.timeframe_minutes = self._parse_timeframes()

    def _parse_timeframes(self) -> dict:
        """–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –ø–∞—Ä—Å–∏—Ç —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        timeframe_map = {}
        timeframes = self.config.get('timeframes', ['1m', '15m', '1h'])

        for tf in timeframes:
            import re
            match = re.match(r'^(\d+)([mhdw])$', tf.lower())

            if not match:
                logger.warning(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∞–π–º—Ñ—Ä–µ–π–º: {tf}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue

            value = int(match.group(1))
            unit = match.group(2)

            if unit == 'm':
                minutes = value
            elif unit == 'h':
                minutes = value * 60
            elif unit == 'd':
                minutes = value * 60 * 24
            elif unit == 'w':
                minutes = value * 60 * 24 * 7
            else:
                logger.warning(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–∞—è –µ–¥–∏–Ω–∏—Ü–∞ –≤—Ä–µ–º–µ–Ω–∏: {unit}")
                continue

            timeframe_map[tf] = minutes

        logger.info(f"–†–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã: {timeframe_map}")
        return timeframe_map

    def load_config(self) -> dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ YAML —Ñ–∞–π–ª–∞"""
        config_path = os.path.join(os.path.dirname(__file__), 'indicators_config.yaml')

        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)

        return config

    def get_table_name(self, timeframe: str) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–º—è —Ç–∞–±–ª–∏—Ü—ã –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞"""
        return f"indicators_bybit_futures_{timeframe}"

    def calculate_williams_r(self, df: pd.DataFrame, period: int) -> pd.Series:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç Williams %R

        –§–æ—Ä–º—É–ª–∞:
        %R = -((High_N - Close) / (High_N - Low_N)) √ó 100

        –î–∏–∞–ø–∞–∑–æ–Ω: –æ—Ç -100 –¥–æ 0
        - Overbought: > -20
        - Oversold: < -80

        Args:
            df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ high, low, close
            period: –ü–µ—Ä–∏–æ–¥ –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ High/Low –¥–∏–∞–ø–∞–∑–æ–Ω–∞

        Returns:
            Series —Å Williams %R –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        """
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º rolling high –∏ low
        rolling_high = df['high'].rolling(window=period).max()
        rolling_low = df['low'].rolling(window=period).min()

        # Williams %R = -((High_N - Close) / (High_N - Low_N)) √ó 100
        # –ò–∑–±–µ–≥–∞–µ–º –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å
        denominator = rolling_high - rolling_low
        wr = np.where(
            denominator != 0,
            -((rolling_high - df['close']) / denominator) * 100,
            np.nan
        )

        return pd.Series(wr, index=df.index)

    def ensure_williams_r_columns(self, timeframe: str, periods: List[int]):
        """
        –°–æ–∑–¥–∞–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è Williams %R –ø–µ—Ä–∏–æ–¥–æ–≤ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç

        Args:
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º (1m, 15m, 1h)
            periods: –°–ø–∏—Å–æ–∫ –ø–µ—Ä–∏–æ–¥–æ–≤ Williams %R
        """
        table_name = self.get_table_name(timeframe)

        with self.db.get_connection() as conn:
            cur = conn.cursor()

            try:
                for period in periods:
                    col_name = f"williamsr_{period}"

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏
                    cur.execute("""
                        SELECT EXISTS (
                            SELECT 1 FROM information_schema.columns
                            WHERE table_schema = 'public'
                            AND table_name = %s
                            AND column_name = %s
                        );
                    """, (table_name, col_name))

                    exists = cur.fetchone()[0]

                    if not exists:
                        logger.info(f"‚ûï –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ {col_name} –≤ —Ç–∞–±–ª–∏—Ü–µ {table_name}")
                        cur.execute(f"""
                            ALTER TABLE {table_name}
                            ADD COLUMN {col_name} DECIMAL(10,4);
                        """)
                        logger.info(f"‚úÖ –ö–æ–ª–æ–Ω–∫–∞ {col_name} —Å–æ–∑–¥–∞–Ω–∞")

                conn.commit()

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∫–æ–ª–æ–Ω–æ–∫ Williams %R: {e}")
                conn.rollback()
                raise
            finally:
                cur.close()

    def get_data_range(self, timeframe: str) -> Tuple[datetime, datetime]:
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–∏–∞–ø–∞–∑–æ–Ω –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        with self.db.get_connection() as conn:
            cur = conn.cursor()

            try:
                cur.execute("""
                    SELECT MIN(timestamp), MAX(timestamp)
                    FROM candles_bybit_futures_1m
                    WHERE symbol = %s
                """, (self.symbol,))

                result = cur.fetchone()

                if not result or result[0] is None:
                    raise ValueError(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {self.symbol} –≤ candles_bybit_futures_1m")

                return result[0], result[1]
            finally:
                cur.close()

    def get_last_williams_r_date(self, timeframe: str, period: int) -> Optional[datetime]:
        """–ü–æ–ª—É—á–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω—é—é –¥–∞—Ç—É —Å —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–º Williams %R"""
        table_name = self.get_table_name(timeframe)
        col_name = f"williamsr_{period}"

        with self.db.get_connection() as conn:
            cur = conn.cursor()

            try:
                cur.execute(f"""
                    SELECT MAX(timestamp)
                    FROM {table_name}
                    WHERE symbol = %s AND {col_name} IS NOT NULL
                """, (self.symbol,))

                result = cur.fetchone()
                return result[0] if result[0] else None
            finally:
                cur.close()

    def get_null_timestamps_for_period(self, timeframe: str, period: int) -> set:
        """
        –ù–∞—Ö–æ–¥–∏—Ç timestamps —Å NULL –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞ Williams %R.
        –ò—Å–∫–ª—é—á–∞–µ—Ç –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ NULL –≤ –Ω–∞—á–∞–ª–µ –¥–∞–Ω–Ω—ã—Ö (–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ lookback).

        Args:
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º
            period: –ü–µ—Ä–∏–æ–¥ Williams %R

        Returns:
            set: –ú–Ω–æ–∂–µ—Å—Ç–≤–æ timestamps —Å NULL
        """
        table_name = self.get_table_name(timeframe)
        col_name = f"williamsr_{period}"
        minutes = self.timeframe_minutes[timeframe]

        with self.db.get_connection() as conn:
            cur = conn.cursor()
            try:
                cur.execute(f"""
                    SELECT MIN(timestamp) FROM {table_name}
                    WHERE symbol = %s
                """, (self.symbol,))
                min_date = cur.fetchone()[0]
                if not min_date:
                    return set()

                boundary = min_date + timedelta(minutes=period * minutes)

                cur.execute(f"""
                    SELECT timestamp FROM {table_name}
                    WHERE symbol = %s
                      AND timestamp >= %s
                      AND {col_name} IS NULL
                """, (self.symbol, boundary))

                return {row[0] for row in cur.fetchall()}
            finally:
                cur.close()

    def get_last_complete_period(self, current_time: datetime, timeframe: str) -> datetime:
        """–ü–æ–ª—É—á–∞–µ—Ç timestamp –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ó–ê–í–ï–†–®–ï–ù–ù–û–ì–û –ø–µ—Ä–∏–æ–¥–∞"""
        minutes = self.timeframe_minutes[timeframe]

        if timeframe == '1m':
            return current_time.replace(second=0, microsecond=0) - timedelta(minutes=1)

        elif timeframe == '15m':
            minute = (current_time.minute // 15) * 15
            result = current_time.replace(minute=minute, second=0, microsecond=0)

            if current_time.minute % 15 == 0 and current_time.second == 0:
                result -= timedelta(minutes=15)

            return result

        elif timeframe == '1h':
            result = current_time.replace(minute=0, second=0, microsecond=0)

            if current_time.minute == 0 and current_time.second == 0:
                result -= timedelta(hours=1)

            return result

        elif timeframe == '4h':
            hour_block = (current_time.hour // 4) * 4
            result = current_time.replace(hour=hour_block, minute=0, second=0, microsecond=0)
            if current_time.hour % 4 == 0 and current_time.minute == 0 and current_time.second == 0:
                result -= timedelta(hours=4)
            return result

        elif timeframe == '1d':
            return (current_time - timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)

        else:
            total_minutes = int(current_time.timestamp() / 60)
            period_start_minutes = (total_minutes // minutes) * minutes
            result = datetime.fromtimestamp(period_start_minutes * 60)

            if total_minutes % minutes == 0:
                result -= timedelta(minutes=minutes)

            return result

    def aggregate_candles(self, start_date: datetime, end_date: datetime, timeframe: str) -> pd.DataFrame:
        """–ê–≥—Ä–µ–≥–∏—Ä—É–µ—Ç –º–∏–Ω—É—Ç–Ω—ã–µ —Å–≤–µ—á–∏ –≤ –Ω—É–∂–Ω—ã–π —Ç–∞–π–º—Ñ—Ä–µ–π–º"""
        with self.db.get_connection() as conn:
            if timeframe == '1m':
                query = """
                    SELECT timestamp, symbol, high, low, close
                    FROM candles_bybit_futures_1m
                    WHERE symbol = %s
                      AND timestamp >= %s
                      AND timestamp <= %s
                    ORDER BY timestamp
                """
                df = pd.read_sql_query(query, conn, params=(self.symbol, start_date, end_date))
            else:
                minutes = self.timeframe_minutes[timeframe]

                # –í–ê–ñ–ù–û: Timestamp = –ù–ê–ß–ê–õ–û –ø–µ—Ä–∏–æ–¥–∞ (Bybit standard)
                if timeframe == '1d':
                    query = """
                        WITH time_groups AS (
                            SELECT
                                timestamp,
                                date_trunc('day', timestamp) as period_start,
                                high, low, close,
                                symbol
                            FROM candles_bybit_futures_1m
                            WHERE symbol = %s
                              AND timestamp >= %s
                              AND timestamp <= %s
                        )
                        SELECT
                            period_start as timestamp,
                            symbol,
                            MAX(high) as high,
                            MIN(low) as low,
                            (ARRAY_AGG(close ORDER BY timestamp DESC))[1] as close
                        FROM time_groups
                        GROUP BY period_start, symbol
                        ORDER BY period_start
                    """
                elif timeframe == '4h':
                    query = """
                        WITH time_groups AS (
                            SELECT
                                timestamp,
                                date_trunc('day', timestamp) +
                                INTERVAL '4 hours' * (EXTRACT(HOUR FROM timestamp)::integer / 4) as period_start,
                                high, low, close,
                                symbol
                            FROM candles_bybit_futures_1m
                            WHERE symbol = %s
                              AND timestamp >= %s
                              AND timestamp <= %s
                        )
                        SELECT
                            period_start as timestamp,
                            symbol,
                            MAX(high) as high,
                            MIN(low) as low,
                            (ARRAY_AGG(close ORDER BY timestamp DESC))[1] as close
                        FROM time_groups
                        GROUP BY period_start, symbol
                        ORDER BY period_start
                    """
                else:
                    query = f"""
                        WITH time_groups AS (
                            SELECT
                                timestamp,
                                DATE_TRUNC('hour', timestamp) +
                                INTERVAL '1 minute' * (FLOOR(EXTRACT(MINUTE FROM timestamp) / {minutes}) * {minutes}) as period_start,
                                high, low, close,
                                symbol
                            FROM candles_bybit_futures_1m
                            WHERE symbol = %s
                              AND timestamp >= %s
                              AND timestamp <= %s
                        )
                        SELECT
                            period_start as timestamp,
                            symbol,
                            MAX(high) as high,
                            MIN(low) as low,
                            (ARRAY_AGG(close ORDER BY timestamp DESC))[1] as close
                        FROM time_groups
                        GROUP BY period_start, symbol
                        ORDER BY period_start
                    """

                df = pd.read_sql_query(query, conn, params=(self.symbol, start_date, end_date))

            return df

    def save_williams_r_to_db(self, df: pd.DataFrame, table_name: str, period: int):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç Williams %R –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        col_name = f"williamsr_{period}"

        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏ —Å –Ω–µ-NULL –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        df_to_save = df[df[col_name].notna()].copy()

        if len(df_to_save) == 0:
            return

        with self.db.get_connection() as conn:
            cur = conn.cursor()

            try:
                update_query = f"""
                    UPDATE {table_name}
                    SET {col_name} = %s
                    WHERE timestamp = %s AND symbol = %s
                """

                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è batch update
                data = [
                    (
                        float(row[col_name]) if pd.notna(row[col_name]) else None,
                        row['timestamp'],
                        row['symbol']
                    )
                    for _, row in df_to_save.iterrows()
                ]

                # –í—ã–ø–æ–ª–Ω—è–µ–º batch update
                psycopg2.extras.execute_batch(cur, update_query, data, page_size=1000)
                conn.commit()

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ Williams %R period={period}: {e}")
                conn.rollback()
                raise
            finally:
                cur.close()

    def calculate_and_save_williams_r(self, timeframe: str, periods: List[int], batch_days: int = 1):
        """
        –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç Williams %R –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞

        Args:
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º (1m, 15m, 1h)
            periods: –°–ø–∏—Å–æ–∫ –ø–µ—Ä–∏–æ–¥–æ–≤ Williams %R
            batch_days: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –≤ –¥–Ω—è—Ö
        """
        table_name = self.get_table_name(timeframe)

        logger.info(f"üöÄ –ù–∞—á–∞–ª–æ —Ä–∞—Å—á–µ—Ç–∞ Williams %R –¥–ª—è {self.symbol} –Ω–∞ —Ç–∞–π–º—Ñ—Ä–µ–π–º–µ {timeframe}")
        logger.info(f"üìä –ü–µ—Ä–∏–æ–¥—ã: {periods}")
        logger.info(f"üì¶ –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {batch_days} –¥–Ω–µ–π")

        # –ü–æ–ª—É—á–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        min_date, max_date = self.get_data_range(timeframe)
        logger.info(f"üìÖ –î–∏–∞–ø–∞–∑–æ–Ω –¥–∞–Ω–Ω—ã—Ö –≤ –ë–î: {min_date} - {max_date}")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥
        last_complete_period = self.get_last_complete_period(max_date, timeframe)

        if max_date > last_complete_period:
            logger.info(f"‚è∏Ô∏è  –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ max_date –¥–æ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞: {last_complete_period}")
            max_date = last_complete_period

        # –ü–æ–ª—É—á–∞–µ–º lookback multiplier –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        lookback_multiplier = self.config['indicators']['williams_r'].get('lookback_multiplier', 2)

        # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞
        for period in periods:
            logger.info(f"\n{'='*80}")
            logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∫–∞ Williams %R period={period}")
            logger.info(f"{'='*80}")

            null_timestamps = None  # None = –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –≤—Å—ë, set() = —Ç–æ–ª—å–∫–æ NULL timestamps

            # –ï—Å–ª–∏ force_reload - –≤—Å–µ–≥–¥–∞ –Ω–∞—á–∏–Ω–∞–µ–º —Å –Ω–∞—á–∞–ª–∞
            if self.force_reload:
                start_date = min_date
                logger.info(f"üîÑ Williams %R period={period}: FORCE RELOAD - –ø–µ—Ä–µ—Å—á–µ—Ç —Å –Ω–∞—á–∞–ª–∞ –∏—Å—Ç–æ—Ä–∏–∏")
            elif self.check_nulls:
                null_ts = self.get_null_timestamps_for_period(timeframe, period)
                if not null_ts:
                    logger.info(f"  ‚úÖ Williams %R period={period}: –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                    continue
                null_timestamps = null_ts
                logger.info(f"üîç Williams %R period={period}: –Ω–∞–π–¥–µ–Ω–æ {len(null_ts)} NULL –∑–∞–ø–∏—Å–µ–π")
                start_date = min(null_ts).replace(hour=0, minute=0, second=0, microsecond=0)
            else:
                # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω—é—é –¥–∞—Ç—É —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è —ç—Ç–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞
                last_date = self.get_last_williams_r_date(timeframe, period)

                if last_date:
                    start_date = last_date + timedelta(days=1)
                    start_date = start_date.replace(hour=0, minute=0, second=0, microsecond=0)
                    logger.info(f"üìÖ –ü–æ—Å–ª–µ–¥–Ω—è—è –¥–∞—Ç–∞ Williams %R period={period}: {last_date}")
                    logger.info(f"‚ñ∂Ô∏è  –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å: {start_date}")
                else:
                    start_date = min_date
                    logger.info(f"üÜï Williams %R period={period} –ø—É—Å—Ç, –Ω–∞—á–∏–Ω–∞–µ–º —Å –Ω–∞—á–∞–ª–∞: {start_date}")

            # –ï—Å–ª–∏ —É–∂–µ –≤—Å–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ
            if start_date > max_date:
                logger.info(f"‚úÖ Williams %R period={period} —É–∂–µ –∞–∫—Ç—É–∞–ª–µ–Ω (–¥–æ {max_date})")
                continue

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            total_days = (max_date.date() - start_date.date()).days + 1
            logger.info(f"üìÜ –í—Å–µ–≥–æ –¥–Ω–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {total_days}")

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á–∞–º–∏
            current_date = start_date
            processed_days = 0
            total_records = 0

            # Lookback –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Ä–∞—Å—á–µ—Ç–∞
            lookback_periods = period * lookback_multiplier
            lookback_minutes = lookback_periods * self.timeframe_minutes[timeframe]
            lookback_delta = timedelta(minutes=lookback_minutes)

            logger.info(f"üîô Lookback –ø–µ—Ä–∏–æ–¥: {lookback_minutes} –º–∏–Ω—É—Ç ({lookback_periods} –ø–µ—Ä–∏–æ–¥–æ–≤ √ó {self.timeframe_minutes[timeframe]} –º–∏–Ω)")

            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –ø–µ—Ä–∏–æ–¥–æ–≤ –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
            periods_str = ','.join(map(str, periods))

            with tqdm(total=total_days,
                     desc=f"{self.symbol} {self.symbol_progress} WILLIAMS[{periods_str}] {timeframe.upper()}",
                     unit="day",
                     bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}] {postfix}') as pbar:
                while current_date <= max_date:
                    batch_end = min(
                        current_date + timedelta(days=batch_days) - timedelta(seconds=1),
                        max_date
                    )

                    data_start = current_date - lookback_delta

                    try:
                        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å lookback
                        df = self.aggregate_candles(data_start, batch_end, timeframe)

                        if len(df) == 0:
                            current_date += timedelta(days=batch_days)
                            processed_days += batch_days
                            pbar.update(min(batch_days, total_days - processed_days + batch_days))
                            continue

                        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º Williams %R
                        wr_values = self.calculate_williams_r(df, period)

                        # –î–æ–±–∞–≤–ª—è–µ–º –∫ DataFrame
                        df[f'williamsr_{period}'] = wr_values

                        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ü–µ–ª–µ–≤–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω (–±–µ–∑ lookback)
                        df_to_save = df[df['timestamp'] >= current_date].copy()

                        # –í —Ä–µ–∂–∏–º–µ check_nulls –∑–∞–ø–∏—Å—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ NULL timestamps
                        if null_timestamps is not None and not df_to_save.empty:
                            df_to_save = df_to_save[df_to_save['timestamp'].isin(null_timestamps)]

                        if df_to_save.empty:
                            current_date += timedelta(days=batch_days)
                            processed_days += batch_days
                            pbar.update(min(batch_days, total_days - processed_days + batch_days))
                            continue

                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å retry –ª–æ–≥–∏–∫–æ–π
                        max_retries = 3
                        for attempt in range(max_retries):
                            try:
                                self.save_williams_r_to_db(df_to_save, table_name, period)
                                break
                            except Exception as e:
                                if attempt < max_retries - 1:
                                    wait_time = 2 ** attempt
                                    time.sleep(wait_time)
                                else:
                                    logger.error(f"‚ùå –í—Å–µ {max_retries} –ø–æ–ø—ã—Ç–∫–∏ –Ω–µ —É–¥–∞–ª–∏—Å—å –¥–ª—è –±–∞—Ç—á–∞ {current_date.date()}")
                                    raise

                        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                        days_in_batch = min(batch_days, (max_date.date() - current_date.date()).days + 1)
                        processed_days += days_in_batch
                        total_records += len(df_to_save)
                        pbar.update(days_in_batch)

                        # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ progress bar
                        if not df_to_save.empty:
                            latest_timestamp = df_to_save['timestamp'].max()
                            pbar.set_postfix({
                                '–≤—Å–µ–≥–æ': f'{total_records:,}',
                                '–ø–æ—Å–ª–µ–¥–Ω—è—è': latest_timestamp.strftime('%Y-%m-%d %H:%M')
                            })

                    except Exception as e:
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –±–∞—Ç—á–∞ {current_date.date()}: {e}")
                        raise

                    current_date += timedelta(days=batch_days)

            logger.info(f"‚úÖ Williams %R period={period} –∑–∞–≤–µ—Ä—à–µ–Ω: {total_records:,} –∑–∞–ø–∏—Å–µ–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞ {processed_days} –¥–Ω–µ–π")

        logger.info(f"\n{'='*80}")
        logger.info(f"üéâ –í—Å–µ –ø–µ—Ä–∏–æ–¥—ã Williams %R –¥–ª—è {timeframe} –∑–∞–≤–µ—Ä—à–µ–Ω—ã!")
        logger.info(f"{'='*80}")

    def run(self, timeframe: str = None, batch_days: int = None):
        """
        –ó–∞–ø—É—Å–∫ –∑–∞–≥—Ä—É–∑–∫–∏ Williams %R

        Args:
            timeframe: –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ç–∞–π–º—Ñ—Ä–µ–π–º –∏–ª–∏ None –¥–ª—è –≤—Å–µ—Ö
            batch_days: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –≤ –¥–Ω—è—Ö
        """
        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        williams_config = self.config['indicators']['williams_r']
        periods = williams_config['periods']

        if batch_days is None:
            batch_days = williams_config.get('batch_days', 1)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if timeframe:
            timeframes = [timeframe]
        else:
            timeframes = self.config.get('timeframes', ['1m', '15m', '1h'])

        logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ Williams %R Loader –¥–ª—è {self.symbol}")
        logger.info(f"‚è∞ –¢–∞–π–º—Ñ—Ä–µ–π–º—ã: {timeframes}")
        logger.info(f"üìä –ü–µ—Ä–∏–æ–¥—ã: {periods}")
        logger.info(f"üì¶ Batch size: {batch_days} –¥–Ω–µ–π")

        for tf in timeframes:
            logger.info(f"\n{'#'*80}")
            logger.info(f"‚è∞ –¢–∞–π–º—Ñ—Ä–µ–π–º: {tf}")
            logger.info(f"{'#'*80}")

            # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            self.ensure_williams_r_columns(tf, periods)

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º Williams %R
            self.calculate_and_save_williams_r(tf, periods, batch_days)

        logger.info(f"\n{'#'*80}")
        logger.info(f"üéâ –ó–∞–≥—Ä—É–∑–∫–∞ Williams %R –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –≤—Å–µ—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤!")
        logger.info(f"{'#'*80}")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description='Stochastic & Williams %R Loader –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤')
    parser.add_argument('--symbol', type=str, default=None,
                       help='–û–¥–Ω–∞ —Ç–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, BTCUSDT)')
    parser.add_argument('--symbols', type=str, default=None,
                       help='–ù–µ—Å–∫–æ–ª—å–∫–æ —Ç–æ—Ä–≥–æ–≤—ã—Ö –ø–∞—Ä —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é (–Ω–∞–ø—Ä–∏–º–µ—Ä, BTCUSDT,ETHUSDT)')
    parser.add_argument('--timeframe', type=str, help='–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ç–∞–π–º—Ñ—Ä–µ–π–º (1m, 15m, 1h)')
    parser.add_argument('--batch-days', type=int, help='–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –≤ –¥–Ω—è—Ö')
    parser.add_argument('--indicator', type=str, choices=['stochastic', 'williams', 'both'], default='both',
                       help='–ö–∞–∫–æ–π –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–∞—Ç—å: stochastic, williams, –∏–ª–∏ both (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é both)')
    parser.add_argument('--force-reload', action='store_true',
                       help='–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø–µ—Ä–µ—Å—á–µ—Ç –í–°–ï–• –¥–∞–Ω–Ω—ã—Ö —Å –Ω–∞—á–∞–ª–∞ –∏—Å—Ç–æ—Ä–∏–∏')
    parser.add_argument('--check-nulls', action='store_true',
                       help='–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏ –∑–∞–ø–æ–ª–Ω–∏—Ç—å NULL –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ –¥–∞–Ω–Ω—ã—Ö')

    args = parser.parse_args()

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–∏–º–≤–æ–ª—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    if args.symbols:
        symbols = [s.strip() for s in args.symbols.split(',')]
    elif args.symbol:
        symbols = [args.symbol]
    else:
        config_path = os.path.join(os.path.dirname(__file__), 'indicators_config.yaml')
        if os.path.exists(config_path):
            import yaml
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
                symbols = config.get('symbols', ['BTCUSDT'])
        else:
            symbols = ['BTCUSDT']

    logger.info(f"üéØ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∏–º–≤–æ–ª–æ–≤: {symbols}")
    logger.info(f"üìä –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã: {args.indicator}")
    if args.force_reload:
        logger.info(f"üîÑ –†–µ–∂–∏–º FORCE RELOAD: –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –±—É–¥—É—Ç –ø–µ—Ä–µ—Å—á–∏—Ç–∞–Ω—ã —Å –Ω–∞—á–∞–ª–∞ –∏—Å—Ç–æ—Ä–∏–∏")
    if args.check_nulls:
        logger.info(f"üîç –†–µ–∂–∏–º CHECK NULLS: –ø–æ–∏—Å–∫ –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ NULL –∑–Ω–∞—á–µ–Ω–∏–π –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ –¥–∞–Ω–Ω—ã—Ö")

    # –¶–∏–∫–ª –ø–æ –≤—Å–µ–º —Å–∏–º–≤–æ–ª–∞–º
    total_symbols = len(symbols)
    for idx, symbol in enumerate(symbols, 1):
        logger.info(f"\n{'='*80}")
        logger.info(f"üìä –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Å–∏–º–≤–æ–ª–∞: {symbol} [{idx}/{total_symbols}]")
        logger.info(f"{'='*80}\n")

        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º Stochastic
            if args.indicator in ['stochastic', 'both']:
                logger.info(f"\n{'#'*80}")
                logger.info(f"üìä –ó–∞–≥—Ä—É–∑–∫–∞ Stochastic Oscillator –¥–ª—è {symbol}")
                logger.info(f"{'#'*80}\n")

                stoch_loader = StochasticLoader(symbol=symbol, force_reload=args.force_reload, check_nulls=args.check_nulls)
                stoch_loader.symbol_progress = f"[{idx}/{total_symbols}]"
                stoch_loader.run(timeframe=args.timeframe, batch_days=args.batch_days)

            # –ó–∞–≥—Ä—É–∂–∞–µ–º Williams %R
            if args.indicator in ['williams', 'both']:
                logger.info(f"\n{'#'*80}")
                logger.info(f"üìä –ó–∞–≥—Ä—É–∑–∫–∞ Williams %R –¥–ª—è {symbol}")
                logger.info(f"{'#'*80}\n")

                williams_loader = WilliamsRLoader(symbol=symbol, force_reload=args.force_reload, check_nulls=args.check_nulls)
                williams_loader.symbol_progress = f"[{idx}/{total_symbols}]"
                williams_loader.run(timeframe=args.timeframe, batch_days=args.batch_days)

            logger.info(f"\n‚úÖ –°–∏–º–≤–æ–ª {symbol} –æ–±—Ä–∞–±–æ—Ç–∞–Ω\n")
        except KeyboardInterrupt:
            logger.info("\n‚ö†Ô∏è –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º. –ú–æ–∂–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –ø–æ–∑–∂–µ —Å —ç—Ç–æ–≥–æ –º–µ—Å—Ç–∞.")
            sys.exit(0)
        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –¥–ª—è —Å–∏–º–≤–æ–ª–∞ {symbol}: {e}")
            import traceback
            traceback.print_exc()
            continue

    logger.info(f"\nüéâ –í—Å–µ —Å–∏–º–≤–æ–ª—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã: {symbols}")


if __name__ == "__main__":
    main()
