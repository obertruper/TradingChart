#!/usr/bin/env python3
"""
Stochastic Oscillator & Williams %R Loader with Multi-Timeframe Support
=======================================================================
–ó–∞–≥—Ä—É–∑—á–∏–∫ Stochastic –∏ Williams %R –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π:
- –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π Stochastic (scalping, intraday, fast, classic, swing, fibonacci_swing, position, fibonacci_long)
- –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø–µ—Ä–∏–æ–¥–æ–≤ Williams %R (6, 10, 14, 20, 30)
- –ë–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å checkpoint
- –õ—é–±—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ (1m, 15m, 1h)
- –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π
- Multi-symbol support

Stochastic Oscillator:
- %K = (Close - Low_N) / (High_N - Low_N) √ó 100
- %K_smooth = SMA(%K, k_smooth)
- %D = SMA(%K_smooth, d_period)

Williams %R:
- %R = -((High_N - Close) / (High_N - Low_N)) √ó 100
- –î–∏–∞–ø–∞–∑–æ–Ω: –æ—Ç -100 –¥–æ 0
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta, timezone
import psycopg2
import psycopg2.extras
from typing import Dict, List, Tuple, Optional
import logging
from tqdm import tqdm
import sys
import os
import warnings
import yaml
import argparse
import time

# –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è pandas
warnings.filterwarnings('ignore', message='pandas only supports SQLAlchemy')

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from indicators.database import DatabaseConnection

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
def setup_logging():
    """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –∫–æ–Ω—Å–æ–ª—å –∏ —Ñ–∞–π–ª"""
    log_dir = os.path.join(os.path.dirname(__file__), 'logs')
    os.makedirs(log_dir, exist_ok=True)

    log_filename = os.path.join(log_dir, f'stochastic_williams_loader_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log')

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler(log_filename, encoding='utf-8')
        ]
    )

    logger = logging.getLogger(__name__)
    logger.info(f"üìù –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ. –õ–æ–≥-—Ñ–∞–π–ª: {log_filename}")

    return logger

logger = setup_logging()


class StochasticLoader:
    """–ó–∞–≥—Ä—É–∑—á–∏–∫ Stochastic Oscillator –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤"""

    def __init__(self, symbol: str = 'BTCUSDT'):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≥—Ä—É–∑—á–∏–∫–∞

        Args:
            symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞
        """
        self.db = DatabaseConnection()
        self.symbol = symbol
        self.symbol_progress = ""  # –î–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø—Ä–∏ multi-symbol
        self.config = self.load_config()

        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –º–∞–ø–∏–Ω–≥ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ –Ω–∞ –º–∏–Ω—É—Ç—ã
        self.timeframe_minutes = self._parse_timeframes()

    def _parse_timeframes(self) -> dict:
        """
        –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –ø–∞—Ä—Å–∏—Ç —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ñ–æ—Ä–º–∞—Ç—ã: 1m, 5m, 15m, 30m, 1h, 4h, 1d, 1w

        Returns:
            dict: –ú–∞–ø–∏–Ω–≥ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–∏–Ω—É—Ç
        """
        timeframe_map = {}

        # –ü–æ–ª—É—á–∞–µ–º —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ
        timeframes = self.config.get('timeframes', ['1m', '15m', '1h'])

        for tf in timeframes:
            # –ü–∞—Ä—Å–∏–º —á–∏—Å–ª–æ –∏ –µ–¥–∏–Ω–∏—Ü—É –∏–∑–º–µ—Ä–µ–Ω–∏—è
            import re
            match = re.match(r'^(\d+)([mhdw])$', tf.lower())

            if not match:
                logger.warning(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∞–π–º—Ñ—Ä–µ–π–º: {tf}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue

            value = int(match.group(1))
            unit = match.group(2)

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –º–∏–Ω—É—Ç—ã
            if unit == 'm':
                minutes = value
            elif unit == 'h':
                minutes = value * 60
            elif unit == 'd':
                minutes = value * 60 * 24
            elif unit == 'w':
                minutes = value * 60 * 24 * 7
            else:
                logger.warning(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–∞—è –µ–¥–∏–Ω–∏—Ü–∞ –≤—Ä–µ–º–µ–Ω–∏: {unit}")
                continue

            timeframe_map[tf] = minutes

        logger.info(f"–†–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã: {timeframe_map}")
        return timeframe_map

    def load_config(self) -> dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ YAML —Ñ–∞–π–ª–∞"""
        config_path = os.path.join(os.path.dirname(__file__), 'indicators_config.yaml')

        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)

        return config

    def get_table_name(self, timeframe: str) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–º—è —Ç–∞–±–ª–∏—Ü—ã –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞"""
        return f"indicators_bybit_futures_{timeframe}"

    def calculate_stochastic(self, df: pd.DataFrame, k_period: int,
                            k_smooth: int, d_period: int) -> Tuple[pd.Series, pd.Series]:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç Stochastic Oscillator (%K –∏ %D)

        –§–æ—Ä–º—É–ª–∞:
        1. %K_raw = (Close - Low_N) / (High_N - Low_N) √ó 100
        2. %K = SMA(%K_raw, k_smooth) –µ—Å–ª–∏ k_smooth > 1, –∏–Ω–∞—á–µ %K = %K_raw
        3. %D = SMA(%K, d_period)

        Args:
            df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ high, low, close
            k_period: –ü–µ—Ä–∏–æ–¥ –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ High/Low –¥–∏–∞–ø–∞–∑–æ–Ω–∞
            k_smooth: –ü–µ—Ä–∏–æ–¥ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è %K (1 = –±–µ–∑ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è)
            d_period: –ü–µ—Ä–∏–æ–¥ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è %D (—Å–∏–≥–Ω–∞–ª—å–Ω–∞—è –ª–∏–Ω–∏—è)

        Returns:
            Tuple[k_values, d_values]: %K –∏ %D –∑–Ω–∞—á–µ–Ω–∏—è
        """
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º rolling high –∏ low
        rolling_high = df['high'].rolling(window=k_period).max()
        rolling_low = df['low'].rolling(window=k_period).min()

        # %K raw (fast stochastic)
        # –ò–∑–±–µ–≥–∞–µ–º –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å
        denominator = rolling_high - rolling_low
        k_raw = np.where(
            denominator != 0,
            ((df['close'] - rolling_low) / denominator) * 100,
            np.nan
        )
        k_raw = pd.Series(k_raw, index=df.index)

        # %K smoothed (slow stochastic)
        if k_smooth > 1:
            k = k_raw.rolling(window=k_smooth).mean()
        else:
            k = k_raw

        # %D (signal line)
        d = k.rolling(window=d_period).mean()

        return k, d

    def ensure_stochastic_columns(self, timeframe: str, configs: List[Dict]):
        """
        –°–æ–∑–¥–∞–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è Stochastic –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç

        Args:
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º (1m, 15m, 1h)
            configs: –°–ø–∏—Å–æ–∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π Stochastic
        """
        table_name = self.get_table_name(timeframe)

        with self.db.get_connection() as conn:
            cur = conn.cursor()

            try:
                for config in configs:
                    k_period = config['k_period']
                    k_smooth = config['k_smooth']
                    d_period = config['d_period']

                    # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º–µ–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫ (—Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã)
                    base_name = f"stoch_{k_period}_{k_smooth}_{d_period}"
                    columns = [
                        f"{base_name}_k",
                        f"{base_name}_d"
                    ]

                    for col_name in columns:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏
                        cur.execute("""
                            SELECT EXISTS (
                                SELECT 1 FROM information_schema.columns
                                WHERE table_schema = 'public'
                                AND table_name = %s
                                AND column_name = %s
                            );
                        """, (table_name, col_name))

                        exists = cur.fetchone()[0]

                        if not exists:
                            logger.info(f"‚ûï –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ {col_name} –≤ —Ç–∞–±–ª–∏—Ü–µ {table_name}")
                            cur.execute(f"""
                                ALTER TABLE {table_name}
                                ADD COLUMN {col_name} DECIMAL(10,4);
                            """)
                            logger.info(f"‚úÖ –ö–æ–ª–æ–Ω–∫–∞ {col_name} —Å–æ–∑–¥–∞–Ω–∞")

                conn.commit()

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∫–æ–ª–æ–Ω–æ–∫: {e}")
                conn.rollback()
                raise
            finally:
                cur.close()

    def get_data_range(self, timeframe: str) -> Tuple[datetime, datetime]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –¥–∏–∞–ø–∞–∑–æ–Ω –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–∑–æ–≤–æ–π —Ç–∞–±–ª–∏—Ü–µ —Å–≤–µ—á–µ–π
        –í—Å–µ–≥–¥–∞ —á–∏—Ç–∞–µ—Ç –∏–∑ candles_bybit_futures_1m

        Returns:
            (min_date, max_date)
        """
        with self.db.get_connection() as conn:
            cur = conn.cursor()

            try:
                cur.execute("""
                    SELECT MIN(timestamp), MAX(timestamp)
                    FROM candles_bybit_futures_1m
                    WHERE symbol = %s
                """, (self.symbol,))

                result = cur.fetchone()

                if not result or result[0] is None:
                    raise ValueError(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {self.symbol} –≤ candles_bybit_futures_1m")

                return result[0], result[1]
            finally:
                cur.close()

    def get_last_stochastic_date(self, timeframe: str, config: Dict) -> Optional[datetime]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω—é—é –¥–∞—Ç—É —Å —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–º Stochastic –¥–ª—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

        Args:
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Stochastic

        Returns:
            –ü–æ—Å–ª–µ–¥–Ω—è—è –¥–∞—Ç–∞ –∏–ª–∏ None
        """
        table_name = self.get_table_name(timeframe)

        k_period = config['k_period']
        k_smooth = config['k_smooth']
        d_period = config['d_period']
        col_name = f"stoch_{k_period}_{k_smooth}_{d_period}_k"

        with self.db.get_connection() as conn:
            cur = conn.cursor()

            try:
                cur.execute(f"""
                    SELECT MAX(timestamp)
                    FROM {table_name}
                    WHERE symbol = %s AND {col_name} IS NOT NULL
                """, (self.symbol,))

                result = cur.fetchone()
                return result[0] if result[0] else None
            finally:
                cur.close()

    def get_last_complete_period(self, current_time: datetime, timeframe: str) -> datetime:
        """
        –ü–æ–ª—É—á–∞–µ—Ç timestamp –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ó–ê–í–ï–†–®–ï–ù–ù–û–ì–û –ø–µ—Ä–∏–æ–¥–∞

        Args:
            current_time: –¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è (timezone-aware)
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º

        Returns:
            Timestamp –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞
        """
        minutes = self.timeframe_minutes[timeframe]

        if timeframe == '1m':
            return current_time.replace(second=0, microsecond=0) - timedelta(minutes=1)

        elif timeframe == '15m':
            minute = (current_time.minute // 15) * 15
            result = current_time.replace(minute=minute, second=0, microsecond=0)

            if current_time.minute % 15 == 0 and current_time.second == 0:
                result -= timedelta(minutes=15)

            return result

        elif timeframe == '1h':
            result = current_time.replace(minute=0, second=0, microsecond=0)

            if current_time.minute == 0 and current_time.second == 0:
                result -= timedelta(hours=1)

            return result

        else:
            total_minutes = int(current_time.timestamp() / 60)
            period_start_minutes = (total_minutes // minutes) * minutes
            result = datetime.fromtimestamp(period_start_minutes * 60)

            if total_minutes % minutes == 0:
                result -= timedelta(minutes=minutes)

            return result

    def aggregate_candles(self, start_date: datetime, end_date: datetime, timeframe: str) -> pd.DataFrame:
        """
        –ê–≥—Ä–µ–≥–∏—Ä—É–µ—Ç –º–∏–Ω—É—Ç–Ω—ã–µ —Å–≤–µ—á–∏ –≤ –Ω—É–∂–Ω—ã–π —Ç–∞–π–º—Ñ—Ä–µ–π–º –∏–ª–∏ —á–∏—Ç–∞–µ—Ç –Ω–∞–ø—Ä—è–º—É—é

        Args:
            start_date: –ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞
            end_date: –ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞
            timeframe: –¶–µ–ª–µ–≤–æ–π —Ç–∞–π–º—Ñ—Ä–µ–π–º

        Returns:
            DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏: timestamp, symbol, high, low, close
        """
        with self.db.get_connection() as conn:
            if timeframe == '1m':
                # –î–ª—è –º–∏–Ω—É—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —á–∏—Ç–∞–µ–º –Ω–∞–ø—Ä—è–º—É—é
                query = """
                    SELECT timestamp, symbol, high, low, close
                    FROM candles_bybit_futures_1m
                    WHERE symbol = %s
                      AND timestamp >= %s
                      AND timestamp <= %s
                    ORDER BY timestamp
                """
                df = pd.read_sql_query(query, conn, params=(self.symbol, start_date, end_date))
            else:
                # –î–ª—è —Å—Ç–∞—Ä—à–∏—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ –∞–≥—Ä–µ–≥–∏—Ä—É–µ–º –∏–∑ –º–∏–Ω—É—Ç–Ω—ã—Ö
                minutes = self.timeframe_minutes[timeframe]

                query = f"""
                    WITH time_groups AS (
                        SELECT
                            timestamp,
                            DATE_TRUNC('hour', timestamp) +
                            INTERVAL '1 minute' * (FLOOR(EXTRACT(MINUTE FROM timestamp) / {minutes}) * {minutes}) as period_start,
                            high, low, close,
                            symbol
                        FROM candles_bybit_futures_1m
                        WHERE symbol = %s
                          AND timestamp >= %s
                          AND timestamp <= %s
                    )
                    SELECT
                        period_start + INTERVAL '{minutes} minutes' as timestamp,
                        symbol,
                        MAX(high) as high,
                        MIN(low) as low,
                        (ARRAY_AGG(close ORDER BY timestamp DESC))[1] as close
                    FROM time_groups
                    GROUP BY period_start, symbol
                    ORDER BY period_start
                """

                df = pd.read_sql_query(query, conn, params=(self.symbol, start_date, end_date))

            return df

    def save_stochastic_to_db(self, df: pd.DataFrame, table_name: str, config: Dict):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç Stochastic –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö

        Args:
            df: DataFrame —Å Stochastic –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
            table_name: –ò–º—è —Ç–∞–±–ª–∏—Ü—ã
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Stochastic
        """
        k_period = config['k_period']
        k_smooth = config['k_smooth']
        d_period = config['d_period']

        base_name = f"stoch_{k_period}_{k_smooth}_{d_period}"
        col_k = f"{base_name}_k"
        col_d = f"{base_name}_d"

        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏ —Å –Ω–µ-NULL –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        df_to_save = df[df[col_k].notna()].copy()

        if len(df_to_save) == 0:
            return

        with self.db.get_connection() as conn:
            cur = conn.cursor()

            try:
                update_query = f"""
                    UPDATE {table_name}
                    SET {col_k} = %s,
                        {col_d} = %s
                    WHERE timestamp = %s AND symbol = %s
                """

                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è batch update
                data = [
                    (
                        float(row[col_k]) if pd.notna(row[col_k]) else None,
                        float(row[col_d]) if pd.notna(row[col_d]) else None,
                        row['timestamp'],
                        row['symbol']
                    )
                    for _, row in df_to_save.iterrows()
                ]

                # –í—ã–ø–æ–ª–Ω—è–µ–º batch update
                psycopg2.extras.execute_batch(cur, update_query, data, page_size=1000)
                conn.commit()

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ Stochastic {config['name']}: {e}")
                conn.rollback()
                raise
            finally:
                cur.close()

    def calculate_and_save_stochastic(self, timeframe: str, configs: List[Dict], batch_days: int = 1):
        """
        –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç Stochastic –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

        Args:
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º (1m, 15m, 1h)
            configs: –°–ø–∏—Å–æ–∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π Stochastic
            batch_days: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –≤ –¥–Ω—è—Ö
        """
        table_name = self.get_table_name(timeframe)

        logger.info(f"üöÄ –ù–∞—á–∞–ª–æ —Ä–∞—Å—á–µ—Ç–∞ Stochastic –¥–ª—è {self.symbol} –Ω–∞ —Ç–∞–π–º—Ñ—Ä–µ–π–º–µ {timeframe}")
        logger.info(f"üìä –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {[c['name'] for c in configs]}")
        logger.info(f"üì¶ –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {batch_days} –¥–Ω–µ–π")

        # –ü–æ–ª—É—á–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        min_date, max_date = self.get_data_range(timeframe)
        logger.info(f"üìÖ –î–∏–∞–ø–∞–∑–æ–Ω –¥–∞–Ω–Ω—ã—Ö –≤ –ë–î: {min_date} - {max_date}")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥
        last_complete_period = self.get_last_complete_period(max_date, timeframe)

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º max_date –ø–æ—Å–ª–µ–¥–Ω–∏–º –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–º –ø–µ—Ä–∏–æ–¥–æ–º
        if max_date > last_complete_period:
            logger.info(f"‚è∏Ô∏è  –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ max_date –¥–æ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞: {last_complete_period}")
            max_date = last_complete_period

        # –ü–æ–ª—É—á–∞–µ–º lookback multiplier –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        lookback_multiplier = self.config['indicators']['stochastic'].get('lookback_multiplier', 2)

        # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        for config in configs:
            logger.info(f"\n{'='*80}")
            logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {config['name']} ({config['k_period']}, {config['k_smooth']}, {config['d_period']})")
            logger.info(f"{'='*80}")

            # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω—é—é –¥–∞—Ç—É —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è —ç—Ç–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            last_date = self.get_last_stochastic_date(timeframe, config)

            if last_date:
                start_date = last_date + timedelta(days=1)
                start_date = start_date.replace(hour=0, minute=0, second=0, microsecond=0)
                logger.info(f"üìÖ –ü–æ—Å–ª–µ–¥–Ω—è—è –¥–∞—Ç–∞ Stochastic {config['name']}: {last_date}")
                logger.info(f"‚ñ∂Ô∏è  –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å: {start_date}")
            else:
                start_date = min_date
                logger.info(f"üÜï Stochastic {config['name']} –ø—É—Å—Ç, –Ω–∞—á–∏–Ω–∞–µ–º —Å –Ω–∞—á–∞–ª–∞: {start_date}")

            # –ï—Å–ª–∏ —É–∂–µ –≤—Å–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ
            if start_date > max_date:
                logger.info(f"‚úÖ Stochastic {config['name']} —É–∂–µ –∞–∫—Ç—É–∞–ª–µ–Ω (–¥–æ {max_date})")
                continue

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            total_days = (max_date.date() - start_date.date()).days + 1
            logger.info(f"üìÜ –í—Å–µ–≥–æ –¥–Ω–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {total_days}")

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á–∞–º–∏
            current_date = start_date
            processed_days = 0
            total_records = 0

            # Lookback –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Ä–∞—Å—á–µ—Ç–∞
            max_period = max(config['k_period'], config['k_smooth'], config['d_period'])
            lookback_periods = max_period * lookback_multiplier
            lookback_minutes = lookback_periods * self.timeframe_minutes[timeframe]
            lookback_delta = timedelta(minutes=lookback_minutes)

            logger.info(f"üîô Lookback –ø–µ—Ä–∏–æ–¥: {lookback_minutes} –º–∏–Ω—É—Ç ({lookback_periods} –ø–µ—Ä–∏–æ–¥–æ–≤ √ó {self.timeframe_minutes[timeframe]} –º–∏–Ω)")

            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
            config_names = [f"{c['k_period']}_{c['k_smooth']}_{c['d_period']}" for c in configs]
            config_list_str = ','.join(config_names)

            with tqdm(total=total_days,
                     desc=f"{self.symbol} {self.symbol_progress} STOCH[{config_list_str}] {timeframe.upper()}",
                     unit="day",
                     bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}] {postfix}') as pbar:
                while current_date <= max_date:
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω–µ—Ü –±–∞—Ç—á–∞
                    batch_end = min(
                        current_date + timedelta(days=batch_days) - timedelta(seconds=1),
                        max_date
                    )

                    # –î–æ–±–∞–≤–ª—è–µ–º lookback –∫ –Ω–∞—á–∞–ª—É –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Ä–∞—Å—á–µ—Ç–∞
                    data_start = current_date - lookback_delta

                    try:
                        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å lookback
                        df = self.aggregate_candles(data_start, batch_end, timeframe)

                        if len(df) == 0:
                            current_date += timedelta(days=batch_days)
                            processed_days += batch_days
                            pbar.update(min(batch_days, total_days - processed_days + batch_days))
                            continue

                        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º Stochastic
                        k_values, d_values = self.calculate_stochastic(
                            df,
                            config['k_period'],
                            config['k_smooth'],
                            config['d_period']
                        )

                        # –î–æ–±–∞–≤–ª—è–µ–º –∫ DataFrame
                        base_name = f"stoch_{config['k_period']}_{config['k_smooth']}_{config['d_period']}"
                        df[f'{base_name}_k'] = k_values
                        df[f'{base_name}_d'] = d_values

                        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ü–µ–ª–µ–≤–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω (–±–µ–∑ lookback)
                        df_to_save = df[df['timestamp'] >= current_date].copy()

                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å retry –ª–æ–≥–∏–∫–æ–π
                        max_retries = 3
                        for attempt in range(max_retries):
                            try:
                                self.save_stochastic_to_db(df_to_save, table_name, config)
                                break
                            except Exception as e:
                                if attempt < max_retries - 1:
                                    wait_time = 2 ** attempt
                                    time.sleep(wait_time)
                                else:
                                    logger.error(f"‚ùå –í—Å–µ {max_retries} –ø–æ–ø—ã—Ç–∫–∏ –Ω–µ —É–¥–∞–ª–∏—Å—å –¥–ª—è –±–∞—Ç—á–∞ {current_date.date()}")
                                    raise

                        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                        days_in_batch = min(batch_days, (max_date.date() - current_date.date()).days + 1)
                        processed_days += days_in_batch
                        total_records += len(df_to_save)
                        pbar.update(days_in_batch)

                        # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ progress bar
                        if not df_to_save.empty:
                            latest_timestamp = df_to_save['timestamp'].max()
                            pbar.set_postfix({
                                '–≤—Å–µ–≥–æ': f'{total_records:,}',
                                '–ø–æ—Å–ª–µ–¥–Ω—è—è': latest_timestamp.strftime('%Y-%m-%d %H:%M')
                            })

                    except Exception as e:
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –±–∞—Ç—á–∞ {current_date.date()}: {e}")
                        raise

                    # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –±–∞—Ç—á—É
                    current_date += timedelta(days=batch_days)

            logger.info(f"‚úÖ Stochastic {config['name']} –∑–∞–≤–µ—Ä—à–µ–Ω: {total_records:,} –∑–∞–ø–∏—Å–µ–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞ {processed_days} –¥–Ω–µ–π")

        logger.info(f"\n{'='*80}")
        logger.info(f"üéâ –í—Å–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ Stochastic –¥–ª—è {timeframe} –∑–∞–≤–µ—Ä—à–µ–Ω—ã!")
        logger.info(f"{'='*80}")

    def run(self, timeframe: str = None, batch_days: int = None):
        """
        –ó–∞–ø—É—Å–∫ –∑–∞–≥—Ä—É–∑–∫–∏ Stochastic

        Args:
            timeframe: –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ç–∞–π–º—Ñ—Ä–µ–π–º –∏–ª–∏ None –¥–ª—è –≤—Å–µ—Ö
            batch_days: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –≤ –¥–Ω—è—Ö
        """
        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        stochastic_config = self.config['indicators']['stochastic']
        configs = stochastic_config['configurations']

        if batch_days is None:
            batch_days = stochastic_config.get('batch_days', 1)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if timeframe:
            timeframes = [timeframe]
        else:
            timeframes = self.config.get('timeframes', ['1m', '15m', '1h'])

        logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ Stochastic Loader –¥–ª—è {self.symbol}")
        logger.info(f"‚è∞ –¢–∞–π–º—Ñ—Ä–µ–π–º—ã: {timeframes}")
        logger.info(f"üìä –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {[c['name'] for c in configs]}")
        logger.info(f"üì¶ Batch size: {batch_days} –¥–Ω–µ–π")

        for tf in timeframes:
            logger.info(f"\n{'#'*80}")
            logger.info(f"‚è∞ –¢–∞–π–º—Ñ—Ä–µ–π–º: {tf}")
            logger.info(f"{'#'*80}")

            # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            self.ensure_stochastic_columns(tf, configs)

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º Stochastic
            self.calculate_and_save_stochastic(tf, configs, batch_days)

        logger.info(f"\n{'#'*80}")
        logger.info(f"üéâ –ó–∞–≥—Ä—É–∑–∫–∞ Stochastic –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –≤—Å–µ—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤!")
        logger.info(f"{'#'*80}")


class WilliamsRLoader:
    """–ó–∞–≥—Ä—É–∑—á–∏–∫ Williams %R –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤"""

    def __init__(self, symbol: str = 'BTCUSDT'):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≥—Ä—É–∑—á–∏–∫–∞

        Args:
            symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞
        """
        self.db = DatabaseConnection()
        self.symbol = symbol
        self.symbol_progress = ""  # –î–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø—Ä–∏ multi-symbol
        self.config = self.load_config()

        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –º–∞–ø–∏–Ω–≥ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ –Ω–∞ –º–∏–Ω—É—Ç—ã
        self.timeframe_minutes = self._parse_timeframes()

    def _parse_timeframes(self) -> dict:
        """–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –ø–∞—Ä—Å–∏—Ç —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        timeframe_map = {}
        timeframes = self.config.get('timeframes', ['1m', '15m', '1h'])

        for tf in timeframes:
            import re
            match = re.match(r'^(\d+)([mhdw])$', tf.lower())

            if not match:
                logger.warning(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∞–π–º—Ñ—Ä–µ–π–º: {tf}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue

            value = int(match.group(1))
            unit = match.group(2)

            if unit == 'm':
                minutes = value
            elif unit == 'h':
                minutes = value * 60
            elif unit == 'd':
                minutes = value * 60 * 24
            elif unit == 'w':
                minutes = value * 60 * 24 * 7
            else:
                logger.warning(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–∞—è –µ–¥–∏–Ω–∏—Ü–∞ –≤—Ä–µ–º–µ–Ω–∏: {unit}")
                continue

            timeframe_map[tf] = minutes

        logger.info(f"–†–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã: {timeframe_map}")
        return timeframe_map

    def load_config(self) -> dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ YAML —Ñ–∞–π–ª–∞"""
        config_path = os.path.join(os.path.dirname(__file__), 'indicators_config.yaml')

        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)

        return config

    def get_table_name(self, timeframe: str) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–º—è —Ç–∞–±–ª–∏—Ü—ã –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞"""
        return f"indicators_bybit_futures_{timeframe}"

    def calculate_williams_r(self, df: pd.DataFrame, period: int) -> pd.Series:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç Williams %R

        –§–æ—Ä–º—É–ª–∞:
        %R = -((High_N - Close) / (High_N - Low_N)) √ó 100

        –î–∏–∞–ø–∞–∑–æ–Ω: –æ—Ç -100 –¥–æ 0
        - Overbought: > -20
        - Oversold: < -80

        Args:
            df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ high, low, close
            period: –ü–µ—Ä–∏–æ–¥ –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ High/Low –¥–∏–∞–ø–∞–∑–æ–Ω–∞

        Returns:
            Series —Å Williams %R –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        """
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º rolling high –∏ low
        rolling_high = df['high'].rolling(window=period).max()
        rolling_low = df['low'].rolling(window=period).min()

        # Williams %R = -((High_N - Close) / (High_N - Low_N)) √ó 100
        # –ò–∑–±–µ–≥–∞–µ–º –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å
        denominator = rolling_high - rolling_low
        wr = np.where(
            denominator != 0,
            -((rolling_high - df['close']) / denominator) * 100,
            np.nan
        )

        return pd.Series(wr, index=df.index)

    def ensure_williams_r_columns(self, timeframe: str, periods: List[int]):
        """
        –°–æ–∑–¥–∞–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è Williams %R –ø–µ—Ä–∏–æ–¥–æ–≤ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç

        Args:
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º (1m, 15m, 1h)
            periods: –°–ø–∏—Å–æ–∫ –ø–µ—Ä–∏–æ–¥–æ–≤ Williams %R
        """
        table_name = self.get_table_name(timeframe)

        with self.db.get_connection() as conn:
            cur = conn.cursor()

            try:
                for period in periods:
                    col_name = f"williamsr_{period}"

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏
                    cur.execute("""
                        SELECT EXISTS (
                            SELECT 1 FROM information_schema.columns
                            WHERE table_schema = 'public'
                            AND table_name = %s
                            AND column_name = %s
                        );
                    """, (table_name, col_name))

                    exists = cur.fetchone()[0]

                    if not exists:
                        logger.info(f"‚ûï –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ {col_name} –≤ —Ç–∞–±–ª–∏—Ü–µ {table_name}")
                        cur.execute(f"""
                            ALTER TABLE {table_name}
                            ADD COLUMN {col_name} DECIMAL(10,4);
                        """)
                        logger.info(f"‚úÖ –ö–æ–ª–æ–Ω–∫–∞ {col_name} —Å–æ–∑–¥–∞–Ω–∞")

                conn.commit()

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∫–æ–ª–æ–Ω–æ–∫ Williams %R: {e}")
                conn.rollback()
                raise
            finally:
                cur.close()

    def get_data_range(self, timeframe: str) -> Tuple[datetime, datetime]:
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–∏–∞–ø–∞–∑–æ–Ω –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        with self.db.get_connection() as conn:
            cur = conn.cursor()

            try:
                cur.execute("""
                    SELECT MIN(timestamp), MAX(timestamp)
                    FROM candles_bybit_futures_1m
                    WHERE symbol = %s
                """, (self.symbol,))

                result = cur.fetchone()

                if not result or result[0] is None:
                    raise ValueError(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {self.symbol} –≤ candles_bybit_futures_1m")

                return result[0], result[1]
            finally:
                cur.close()

    def get_last_williams_r_date(self, timeframe: str, period: int) -> Optional[datetime]:
        """–ü–æ–ª—É—á–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω—é—é –¥–∞—Ç—É —Å —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–º Williams %R"""
        table_name = self.get_table_name(timeframe)
        col_name = f"williamsr_{period}"

        with self.db.get_connection() as conn:
            cur = conn.cursor()

            try:
                cur.execute(f"""
                    SELECT MAX(timestamp)
                    FROM {table_name}
                    WHERE symbol = %s AND {col_name} IS NOT NULL
                """, (self.symbol,))

                result = cur.fetchone()
                return result[0] if result[0] else None
            finally:
                cur.close()

    def get_last_complete_period(self, current_time: datetime, timeframe: str) -> datetime:
        """–ü–æ–ª—É—á–∞–µ—Ç timestamp –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ó–ê–í–ï–†–®–ï–ù–ù–û–ì–û –ø–µ—Ä–∏–æ–¥–∞"""
        minutes = self.timeframe_minutes[timeframe]

        if timeframe == '1m':
            return current_time.replace(second=0, microsecond=0) - timedelta(minutes=1)

        elif timeframe == '15m':
            minute = (current_time.minute // 15) * 15
            result = current_time.replace(minute=minute, second=0, microsecond=0)

            if current_time.minute % 15 == 0 and current_time.second == 0:
                result -= timedelta(minutes=15)

            return result

        elif timeframe == '1h':
            result = current_time.replace(minute=0, second=0, microsecond=0)

            if current_time.minute == 0 and current_time.second == 0:
                result -= timedelta(hours=1)

            return result

        else:
            total_minutes = int(current_time.timestamp() / 60)
            period_start_minutes = (total_minutes // minutes) * minutes
            result = datetime.fromtimestamp(period_start_minutes * 60)

            if total_minutes % minutes == 0:
                result -= timedelta(minutes=minutes)

            return result

    def aggregate_candles(self, start_date: datetime, end_date: datetime, timeframe: str) -> pd.DataFrame:
        """–ê–≥—Ä–µ–≥–∏—Ä—É–µ—Ç –º–∏–Ω—É—Ç–Ω—ã–µ —Å–≤–µ—á–∏ –≤ –Ω—É–∂–Ω—ã–π —Ç–∞–π–º—Ñ—Ä–µ–π–º"""
        with self.db.get_connection() as conn:
            if timeframe == '1m':
                query = """
                    SELECT timestamp, symbol, high, low, close
                    FROM candles_bybit_futures_1m
                    WHERE symbol = %s
                      AND timestamp >= %s
                      AND timestamp <= %s
                    ORDER BY timestamp
                """
                df = pd.read_sql_query(query, conn, params=(self.symbol, start_date, end_date))
            else:
                minutes = self.timeframe_minutes[timeframe]

                query = f"""
                    WITH time_groups AS (
                        SELECT
                            timestamp,
                            DATE_TRUNC('hour', timestamp) +
                            INTERVAL '1 minute' * (FLOOR(EXTRACT(MINUTE FROM timestamp) / {minutes}) * {minutes}) as period_start,
                            high, low, close,
                            symbol
                        FROM candles_bybit_futures_1m
                        WHERE symbol = %s
                          AND timestamp >= %s
                          AND timestamp <= %s
                    )
                    SELECT
                        period_start + INTERVAL '{minutes} minutes' as timestamp,
                        symbol,
                        MAX(high) as high,
                        MIN(low) as low,
                        (ARRAY_AGG(close ORDER BY timestamp DESC))[1] as close
                    FROM time_groups
                    GROUP BY period_start, symbol
                    ORDER BY period_start
                """

                df = pd.read_sql_query(query, conn, params=(self.symbol, start_date, end_date))

            return df

    def save_williams_r_to_db(self, df: pd.DataFrame, table_name: str, period: int):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç Williams %R –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        col_name = f"williamsr_{period}"

        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏ —Å –Ω–µ-NULL –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        df_to_save = df[df[col_name].notna()].copy()

        if len(df_to_save) == 0:
            return

        with self.db.get_connection() as conn:
            cur = conn.cursor()

            try:
                update_query = f"""
                    UPDATE {table_name}
                    SET {col_name} = %s
                    WHERE timestamp = %s AND symbol = %s
                """

                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è batch update
                data = [
                    (
                        float(row[col_name]) if pd.notna(row[col_name]) else None,
                        row['timestamp'],
                        row['symbol']
                    )
                    for _, row in df_to_save.iterrows()
                ]

                # –í—ã–ø–æ–ª–Ω—è–µ–º batch update
                psycopg2.extras.execute_batch(cur, update_query, data, page_size=1000)
                conn.commit()

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ Williams %R period={period}: {e}")
                conn.rollback()
                raise
            finally:
                cur.close()

    def calculate_and_save_williams_r(self, timeframe: str, periods: List[int], batch_days: int = 1):
        """
        –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç Williams %R –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞

        Args:
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º (1m, 15m, 1h)
            periods: –°–ø–∏—Å–æ–∫ –ø–µ—Ä–∏–æ–¥–æ–≤ Williams %R
            batch_days: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –≤ –¥–Ω—è—Ö
        """
        table_name = self.get_table_name(timeframe)

        logger.info(f"üöÄ –ù–∞—á–∞–ª–æ —Ä–∞—Å—á–µ—Ç–∞ Williams %R –¥–ª—è {self.symbol} –Ω–∞ —Ç–∞–π–º—Ñ—Ä–µ–π–º–µ {timeframe}")
        logger.info(f"üìä –ü–µ—Ä–∏–æ–¥—ã: {periods}")
        logger.info(f"üì¶ –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {batch_days} –¥–Ω–µ–π")

        # –ü–æ–ª—É—á–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        min_date, max_date = self.get_data_range(timeframe)
        logger.info(f"üìÖ –î–∏–∞–ø–∞–∑–æ–Ω –¥–∞–Ω–Ω—ã—Ö –≤ –ë–î: {min_date} - {max_date}")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥
        last_complete_period = self.get_last_complete_period(max_date, timeframe)

        if max_date > last_complete_period:
            logger.info(f"‚è∏Ô∏è  –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ max_date –¥–æ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞: {last_complete_period}")
            max_date = last_complete_period

        # –ü–æ–ª—É—á–∞–µ–º lookback multiplier –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        lookback_multiplier = self.config['indicators']['williams_r'].get('lookback_multiplier', 2)

        # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞
        for period in periods:
            logger.info(f"\n{'='*80}")
            logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∫–∞ Williams %R period={period}")
            logger.info(f"{'='*80}")

            # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω—é—é –¥–∞—Ç—É —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è —ç—Ç–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞
            last_date = self.get_last_williams_r_date(timeframe, period)

            if last_date:
                start_date = last_date + timedelta(days=1)
                start_date = start_date.replace(hour=0, minute=0, second=0, microsecond=0)
                logger.info(f"üìÖ –ü–æ—Å–ª–µ–¥–Ω—è—è –¥–∞—Ç–∞ Williams %R period={period}: {last_date}")
                logger.info(f"‚ñ∂Ô∏è  –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å: {start_date}")
            else:
                start_date = min_date
                logger.info(f"üÜï Williams %R period={period} –ø—É—Å—Ç, –Ω–∞—á–∏–Ω–∞–µ–º —Å –Ω–∞—á–∞–ª–∞: {start_date}")

            # –ï—Å–ª–∏ —É–∂–µ –≤—Å–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ
            if start_date > max_date:
                logger.info(f"‚úÖ Williams %R period={period} —É–∂–µ –∞–∫—Ç—É–∞–ª–µ–Ω (–¥–æ {max_date})")
                continue

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            total_days = (max_date.date() - start_date.date()).days + 1
            logger.info(f"üìÜ –í—Å–µ–≥–æ –¥–Ω–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {total_days}")

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á–∞–º–∏
            current_date = start_date
            processed_days = 0
            total_records = 0

            # Lookback –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Ä–∞—Å—á–µ—Ç–∞
            lookback_periods = period * lookback_multiplier
            lookback_minutes = lookback_periods * self.timeframe_minutes[timeframe]
            lookback_delta = timedelta(minutes=lookback_minutes)

            logger.info(f"üîô Lookback –ø–µ—Ä–∏–æ–¥: {lookback_minutes} –º–∏–Ω—É—Ç ({lookback_periods} –ø–µ—Ä–∏–æ–¥–æ–≤ √ó {self.timeframe_minutes[timeframe]} –º–∏–Ω)")

            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –ø–µ—Ä–∏–æ–¥–æ–≤ –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
            periods_str = ','.join(map(str, periods))

            with tqdm(total=total_days,
                     desc=f"{self.symbol} {self.symbol_progress} WILLIAMS[{periods_str}] {timeframe.upper()}",
                     unit="day",
                     bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}] {postfix}') as pbar:
                while current_date <= max_date:
                    batch_end = min(
                        current_date + timedelta(days=batch_days) - timedelta(seconds=1),
                        max_date
                    )

                    data_start = current_date - lookback_delta

                    try:
                        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å lookback
                        df = self.aggregate_candles(data_start, batch_end, timeframe)

                        if len(df) == 0:
                            current_date += timedelta(days=batch_days)
                            processed_days += batch_days
                            pbar.update(min(batch_days, total_days - processed_days + batch_days))
                            continue

                        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º Williams %R
                        wr_values = self.calculate_williams_r(df, period)

                        # –î–æ–±–∞–≤–ª—è–µ–º –∫ DataFrame
                        df[f'williamsr_{period}'] = wr_values

                        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ü–µ–ª–µ–≤–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω (–±–µ–∑ lookback)
                        df_to_save = df[df['timestamp'] >= current_date].copy()

                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å retry –ª–æ–≥–∏–∫–æ–π
                        max_retries = 3
                        for attempt in range(max_retries):
                            try:
                                self.save_williams_r_to_db(df_to_save, table_name, period)
                                break
                            except Exception as e:
                                if attempt < max_retries - 1:
                                    wait_time = 2 ** attempt
                                    time.sleep(wait_time)
                                else:
                                    logger.error(f"‚ùå –í—Å–µ {max_retries} –ø–æ–ø—ã—Ç–∫–∏ –Ω–µ —É–¥–∞–ª–∏—Å—å –¥–ª—è –±–∞—Ç—á–∞ {current_date.date()}")
                                    raise

                        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                        days_in_batch = min(batch_days, (max_date.date() - current_date.date()).days + 1)
                        processed_days += days_in_batch
                        total_records += len(df_to_save)
                        pbar.update(days_in_batch)

                        # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ progress bar
                        if not df_to_save.empty:
                            latest_timestamp = df_to_save['timestamp'].max()
                            pbar.set_postfix({
                                '–≤—Å–µ–≥–æ': f'{total_records:,}',
                                '–ø–æ—Å–ª–µ–¥–Ω—è—è': latest_timestamp.strftime('%Y-%m-%d %H:%M')
                            })

                    except Exception as e:
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –±–∞—Ç—á–∞ {current_date.date()}: {e}")
                        raise

                    current_date += timedelta(days=batch_days)

            logger.info(f"‚úÖ Williams %R period={period} –∑–∞–≤–µ—Ä—à–µ–Ω: {total_records:,} –∑–∞–ø–∏—Å–µ–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞ {processed_days} –¥–Ω–µ–π")

        logger.info(f"\n{'='*80}")
        logger.info(f"üéâ –í—Å–µ –ø–µ—Ä–∏–æ–¥—ã Williams %R –¥–ª—è {timeframe} –∑–∞–≤–µ—Ä—à–µ–Ω—ã!")
        logger.info(f"{'='*80}")

    def run(self, timeframe: str = None, batch_days: int = None):
        """
        –ó–∞–ø—É—Å–∫ –∑–∞–≥—Ä—É–∑–∫–∏ Williams %R

        Args:
            timeframe: –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ç–∞–π–º—Ñ—Ä–µ–π–º –∏–ª–∏ None –¥–ª—è –≤—Å–µ—Ö
            batch_days: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –≤ –¥–Ω—è—Ö
        """
        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        williams_config = self.config['indicators']['williams_r']
        periods = williams_config['periods']

        if batch_days is None:
            batch_days = williams_config.get('batch_days', 1)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if timeframe:
            timeframes = [timeframe]
        else:
            timeframes = self.config.get('timeframes', ['1m', '15m', '1h'])

        logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ Williams %R Loader –¥–ª—è {self.symbol}")
        logger.info(f"‚è∞ –¢–∞–π–º—Ñ—Ä–µ–π–º—ã: {timeframes}")
        logger.info(f"üìä –ü–µ—Ä–∏–æ–¥—ã: {periods}")
        logger.info(f"üì¶ Batch size: {batch_days} –¥–Ω–µ–π")

        for tf in timeframes:
            logger.info(f"\n{'#'*80}")
            logger.info(f"‚è∞ –¢–∞–π–º—Ñ—Ä–µ–π–º: {tf}")
            logger.info(f"{'#'*80}")

            # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            self.ensure_williams_r_columns(tf, periods)

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º Williams %R
            self.calculate_and_save_williams_r(tf, periods, batch_days)

        logger.info(f"\n{'#'*80}")
        logger.info(f"üéâ –ó–∞–≥—Ä—É–∑–∫–∞ Williams %R –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –≤—Å–µ—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤!")
        logger.info(f"{'#'*80}")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description='Stochastic & Williams %R Loader –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤')
    parser.add_argument('--symbol', type=str, default=None,
                       help='–û–¥–Ω–∞ —Ç–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, BTCUSDT)')
    parser.add_argument('--symbols', type=str, default=None,
                       help='–ù–µ—Å–∫–æ–ª—å–∫–æ —Ç–æ—Ä–≥–æ–≤—ã—Ö –ø–∞—Ä —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é (–Ω–∞–ø—Ä–∏–º–µ—Ä, BTCUSDT,ETHUSDT)')
    parser.add_argument('--timeframe', type=str, help='–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ç–∞–π–º—Ñ—Ä–µ–π–º (1m, 15m, 1h)')
    parser.add_argument('--batch-days', type=int, help='–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –≤ –¥–Ω—è—Ö')
    parser.add_argument('--indicator', type=str, choices=['stochastic', 'williams', 'both'], default='both',
                       help='–ö–∞–∫–æ–π –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–∞—Ç—å: stochastic, williams, –∏–ª–∏ both (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é both)')

    args = parser.parse_args()

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–∏–º–≤–æ–ª—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    if args.symbols:
        symbols = [s.strip() for s in args.symbols.split(',')]
    elif args.symbol:
        symbols = [args.symbol]
    else:
        config_path = os.path.join(os.path.dirname(__file__), 'indicators_config.yaml')
        if os.path.exists(config_path):
            import yaml
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
                symbols = config.get('symbols', ['BTCUSDT'])
        else:
            symbols = ['BTCUSDT']

    logger.info(f"üéØ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∏–º–≤–æ–ª–æ–≤: {symbols}")
    logger.info(f"üìä –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã: {args.indicator}")

    # –¶–∏–∫–ª –ø–æ –≤—Å–µ–º —Å–∏–º–≤–æ–ª–∞–º
    total_symbols = len(symbols)
    for idx, symbol in enumerate(symbols, 1):
        logger.info(f"\n{'='*80}")
        logger.info(f"üìä –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Å–∏–º–≤–æ–ª–∞: {symbol} [{idx}/{total_symbols}]")
        logger.info(f"{'='*80}\n")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º Stochastic
        if args.indicator in ['stochastic', 'both']:
            logger.info(f"\n{'#'*80}")
            logger.info(f"üìä –ó–∞–≥—Ä—É–∑–∫–∞ Stochastic Oscillator –¥–ª—è {symbol}")
            logger.info(f"{'#'*80}\n")

            stoch_loader = StochasticLoader(symbol=symbol)
            stoch_loader.symbol_progress = f"[{idx}/{total_symbols}]"
            stoch_loader.run(timeframe=args.timeframe, batch_days=args.batch_days)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º Williams %R
        if args.indicator in ['williams', 'both']:
            logger.info(f"\n{'#'*80}")
            logger.info(f"üìä –ó–∞–≥—Ä—É–∑–∫–∞ Williams %R –¥–ª—è {symbol}")
            logger.info(f"{'#'*80}\n")

            williams_loader = WilliamsRLoader(symbol=symbol)
            williams_loader.symbol_progress = f"[{idx}/{total_symbols}]"
            williams_loader.run(timeframe=args.timeframe, batch_days=args.batch_days)

        logger.info(f"\n‚úÖ –°–∏–º–≤–æ–ª {symbol} –æ–±—Ä–∞–±–æ—Ç–∞–Ω\n")

    logger.info(f"\nüéâ –í—Å–µ —Å–∏–º–≤–æ–ª—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã: {symbols}")


if __name__ == "__main__":
    main()
