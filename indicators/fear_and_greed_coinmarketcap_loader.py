#!/usr/bin/env python3
"""
CoinMarketCap Fear & Greed Index Loader
–ó–∞–≥—Ä—É–∑—á–∏–∫ –∏–Ω–¥–µ–∫—Å–∞ —Å—Ç—Ä–∞—Ö–∞ –∏ –∂–∞–¥–Ω–æ—Å—Ç–∏ –æ—Ç CoinMarketCap –¥–ª—è –≤—Å–µ—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
"""

import os
import sys
import psycopg2
from psycopg2.extras import RealDictCursor
import yaml
import logging
from datetime import datetime, timezone, timedelta, date
from typing import Optional, Dict, List, Tuple
import requests
import json
from tqdm import tqdm
import time

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


class CoinMarketCapFearGreedLoader:
    """–ó–∞–≥—Ä—É–∑—á–∏–∫ Fear & Greed Index –æ—Ç CoinMarketCap"""

    def __init__(self, config_path: str = 'indicators_config.yaml'):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≥—Ä—É–∑—á–∏–∫–∞

        Args:
            config_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        """
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        self.config_path = config_path
        self.load_config()

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        self.setup_logging()

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î
        self.db_config = self.config['database']

        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è CoinMarketCap API
        self.api_config = self.config.get('indicators', {}).get('coinmarketcap_fear_and_greed', {})
        self.api_key = self.api_config.get('api_key')
        self.base_url = self.api_config.get('base_url', 'https://pro-api.coinmarketcap.com')
        self.batch_size = self.api_config.get('batch_size', 500)
        self.batch_days = self.api_config.get('batch_days', 1)
        self.retry_on_error = self.api_config.get('retry_on_error', 3)

        # –°–∏–º–≤–æ–ª –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (Fear & Greed –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –∫ BTCUSDT)
        self.symbol = 'BTCUSDT'

        # –¢–∞–π–º—Ñ—Ä–µ–π–º—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.timeframes = self.api_config.get('timeframes', ['1m', '15m', '1h'])

        # –ù–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ –≤ –ë–î
        self.index_column = 'fear_and_greed_index_coinmarketcap'
        self.classification_column = 'fear_and_greed_index_coinmarketcap_classification'

        # –ö–µ—à –¥–ª—è API –¥–∞–Ω–Ω—ã—Ö
        self.api_data_cache = None

        # –ö–µ—à –¥–ª—è checkpoint'–æ–≤ (—á—Ç–æ–±—ã –Ω–µ –∑–∞–ø—Ä–∞—à–∏–≤–∞—Ç—å –ø–æ–≤—Ç–æ—Ä–Ω–æ)
        self.checkpoints_cache = None

        self.logger.info("=" * 60)
        self.logger.info("üöÄ –ó–∞–ø—É—Å–∫ CoinMarketCap Fear & Greed Index Loader")
        self.logger.info(f"üéØ –°–∏–º–≤–æ–ª: {self.symbol}")
        self.logger.info(f"‚è±Ô∏è –¢–∞–π–º—Ñ—Ä–µ–π–º—ã: {', '.join(self.timeframes)}")
        self.logger.info("=" * 60)

    def load_config(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ —Ñ–∞–π–ª–∞"""
        config_dir = os.path.dirname(os.path.abspath(__file__))
        config_file = os.path.join(config_dir, self.config_path)

        if not os.path.exists(config_file):
            raise FileNotFoundError(f"–§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {config_file}")

        with open(config_file, 'r') as f:
            self.config = yaml.safe_load(f)

    def setup_logging(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –ª–æ–≥–æ–≤ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        log_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'logs')
        os.makedirs(log_dir, exist_ok=True)

        # –ò–º—è —Ñ–∞–π–ª–∞ –ª–æ–≥–∞ —Å —Ç–µ–∫—É—â–µ–π –¥–∞—Ç–æ–π –∏ –≤—Ä–µ–º–µ–Ω–µ–º
        log_filename = os.path.join(
            log_dir,
            f"coinmarketcap_fear_greed_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        )

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_filename, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )

        self.logger = logging.getLogger(__name__)
        self.logger.info(f"üìù CoinMarketCap Fear & Greed Loader: –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ. –õ–æ–≥-—Ñ–∞–π–ª: {log_filename}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ø–æ—Å–ª–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        config_file = os.path.join(os.path.dirname(os.path.abspath(__file__)), self.config_path)
        self.logger.info(f"üìã –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {config_file}")

    def connect_db(self):
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            conn = psycopg2.connect(
                host=self.db_config['host'],
                port=self.db_config['port'],
                database=self.db_config['database'],
                user=self.db_config['user'],
                password=self.db_config['password']
            )
            return conn
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î: {e}")
            raise

    def create_columns(self) -> bool:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è Fear & Greed Index –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç

        Returns:
            bool: True –µ—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∏ —Å–æ–∑–¥–∞–Ω—ã –∏–ª–∏ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
        """
        self.logger.info("üî® –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ CoinMarketCap Fear & Greed...")

        conn = self.connect_db()
        cursor = conn.cursor()

        try:
            for timeframe in self.timeframes:
                table_name = f'indicators_bybit_futures_{timeframe}'

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã
                cursor.execute("""
                    SELECT EXISTS (
                        SELECT FROM information_schema.tables
                        WHERE table_name = %s
                    )
                """, (table_name,))

                if not cursor.fetchone()[0]:
                    self.logger.error(f"  ‚ùå –¢–∞–±–ª–∏—Ü–∞ {table_name} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
                    return False

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ —Å–æ–∑–¥–∞–µ–º –∫–æ–ª–æ–Ω–∫—É –¥–ª—è –∑–Ω–∞—á–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞
                cursor.execute(f"""
                    SELECT column_name
                    FROM information_schema.columns
                    WHERE table_name = %s AND column_name = %s
                """, (table_name, self.index_column))

                if not cursor.fetchone():
                    cursor.execute(f"""
                        ALTER TABLE {table_name}
                        ADD COLUMN {self.index_column} SMALLINT
                    """)
                    conn.commit()
                    self.logger.info(f"  ‚úÖ –ö–æ–ª–æ–Ω–∫–∞ {self.index_column} —Å–æ–∑–¥–∞–Ω–∞ –≤ {table_name}")
                else:
                    self.logger.info(f"  ‚úÖ –ö–æ–ª–æ–Ω–∫–∞ {self.index_column} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ {table_name}")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ —Å–æ–∑–¥–∞–µ–º –∫–æ–ª–æ–Ω–∫—É –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
                cursor.execute(f"""
                    SELECT column_name
                    FROM information_schema.columns
                    WHERE table_name = %s AND column_name = %s
                """, (table_name, self.classification_column))

                if not cursor.fetchone():
                    cursor.execute(f"""
                        ALTER TABLE {table_name}
                        ADD COLUMN {self.classification_column} VARCHAR(20)
                    """)
                    conn.commit()
                    self.logger.info(f"  ‚úÖ –ö–æ–ª–æ–Ω–∫–∞ {self.classification_column} —Å–æ–∑–¥–∞–Ω–∞ –≤ {table_name}")
                else:
                    self.logger.info(f"  ‚úÖ –ö–æ–ª–æ–Ω–∫–∞ {self.classification_column} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ {table_name}")

            self.logger.info("‚úÖ –í—Å–µ –∫–æ–ª–æ–Ω–∫–∏ –≥–æ—Ç–æ–≤—ã")
            return True

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∫–æ–ª–æ–Ω–æ–∫: {e}")
            conn.rollback()
            return False
        finally:
            cursor.close()
            conn.close()

    def get_api_data(self) -> Optional[Dict]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å API CoinMarketCap

        Returns:
            Dict —Å –¥–∞–Ω–Ω—ã–º–∏ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        if self.api_data_cache:
            self.logger.info("üì¶ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ API")
            return self.api_data_cache

        self.logger.info(f"üì° –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å CoinMarketCap API")

        if not self.api_key:
            self.logger.error("‚ùå API –∫–ª—é—á –Ω–µ —É–∫–∞–∑–∞–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
            return None

        headers = {
            'X-CMC_PRO_API_KEY': self.api_key,
            'Accept': 'application/json'
        }

        all_data = []
        total_credits_used = 0

        try:
            # –ü–µ—Ä–≤—ã–π –±–∞—Ç—á - –ø–æ—Å–ª–µ–¥–Ω–∏–µ 500 –∑–∞–ø–∏—Å–µ–π
            url = f'{self.base_url}/v3/fear-and-greed/historical'
            params = {'limit': self.batch_size}

            self.logger.info(f"  üì• –ó–∞–ø—Ä–æ—Å –±–∞—Ç—á–∞ 1 (limit={self.batch_size})...")
            response = requests.get(url, headers=headers, params=params, timeout=30)

            if response.status_code == 200:
                data = response.json()
                status = data.get('status', {})
                credits = status.get('credit_count', 0)
                total_credits_used += credits

                if 'data' in data and data['data']:
                    batch1 = data['data']
                    all_data.extend(batch1)
                    self.logger.info(f"  ‚úÖ –ë–∞—Ç—á 1: –ø–æ–ª—É—á–µ–Ω–æ {len(batch1)} –∑–∞–ø–∏—Å–µ–π (–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ {credits} –∫—Ä–µ–¥–∏—Ç–æ–≤)")
            else:
                self.logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ API (–±–∞—Ç—á 1): {response.status_code}")
                if response.status_code == 429:
                    self.logger.error("  ‚ö†Ô∏è –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ API")
                elif response.status_code == 401:
                    self.logger.error("  ‚ö†Ô∏è –ù–µ–≤–µ—Ä–Ω—ã–π API –∫–ª—é—á")
                return None

            # –í—Ç–æ—Ä–æ–π –±–∞—Ç—á - —Å–ª–µ–¥—É—é—â–∏–µ –∑–∞–ø–∏—Å–∏
            params = {'start': 500, 'limit': self.batch_size}
            self.logger.info(f"  üì• –ó–∞–ø—Ä–æ—Å –±–∞—Ç—á–∞ 2 (start=500, limit={self.batch_size})...")
            response = requests.get(url, headers=headers, params=params, timeout=30)

            if response.status_code == 200:
                data = response.json()
                status = data.get('status', {})
                credits = status.get('credit_count', 0)
                total_credits_used += credits

                if 'data' in data and data['data']:
                    batch2 = data['data']
                    all_data.extend(batch2)
                    self.logger.info(f"  ‚úÖ –ë–∞—Ç—á 2: –ø–æ–ª—É—á–µ–Ω–æ {len(batch2)} –∑–∞–ø–∏—Å–µ–π (–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ {credits} –∫—Ä–µ–¥–∏—Ç–æ–≤)")
            else:
                self.logger.warning(f"  ‚ö†Ô∏è –ë–∞—Ç—á 2: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –æ—à–∏–±–∫–∞ {response.status_code}")

            if all_data:
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Å–ª–æ–≤–∞—Ä—å –ø–æ –¥–∞—Ç–∞–º
                data_by_date = {}

                for record in all_data:
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º timestamp –≤ –¥–∞—Ç—É
                    ts = int(record['timestamp'])
                    dt = datetime.fromtimestamp(ts, tz=timezone.utc)
                    date_key = dt.date()

                    data_by_date[date_key] = {
                        'value': record['value'],
                        'classification': record['value_classification']
                    }

                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–∞–º
                sorted_dates = sorted(data_by_date.keys())

                self.logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data_by_date)} –¥–Ω–µ–π –¥–∞–Ω–Ω—ã—Ö")
                self.logger.info(f"üìÖ –ü–µ—Ä–∏–æ–¥: {sorted_dates[0]} - {sorted_dates[-1]}")
                self.logger.info(f"üí≥ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –∫—Ä–µ–¥–∏—Ç–æ–≤: {total_credits_used}")

                # –ö–µ—à–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
                self.api_data_cache = data_by_date
                return data_by_date
            else:
                self.logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Å API")
                return None

        except requests.exceptions.RequestException as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ API: {e}")
            return None
        except Exception as e:
            self.logger.error(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
            return None

    def get_all_checkpoints(self) -> Dict[str, Optional[datetime]]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ checkpoint –¥–ª—è –í–°–ï–• —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º (–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è)

        Returns:
            Dict —Å checkpoint'–∞–º–∏: {'1m': datetime, '15m': datetime, '1h': datetime}
        """
        conn = self.connect_db()
        cursor = conn.cursor()

        try:
            # –û–î–ò–ù –∑–∞–ø—Ä–æ—Å –¥–ª—è –≤—Å–µ—Ö 3 —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ —Å UNION ALL
            query = """
                SELECT '1m' as timeframe, DATE(MAX(timestamp)) as max_date
                FROM indicators_bybit_futures_1m
                WHERE symbol = %s AND fear_and_greed_index_coinmarketcap IS NOT NULL

                UNION ALL

                SELECT '15m' as timeframe, DATE(MAX(timestamp)) as max_date
                FROM indicators_bybit_futures_15m
                WHERE symbol = %s AND fear_and_greed_index_coinmarketcap IS NOT NULL

                UNION ALL

                SELECT '1h' as timeframe, DATE(MAX(timestamp)) as max_date
                FROM indicators_bybit_futures_1h
                WHERE symbol = %s AND fear_and_greed_index_coinmarketcap IS NOT NULL
            """

            cursor.execute(query, (self.symbol, self.symbol, self.symbol))
            results = cursor.fetchall()

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ª–æ–≤–∞—Ä—å
            checkpoints = {}
            for timeframe, max_date in results:
                if max_date:
                    checkpoints[timeframe] = datetime.combine(
                        max_date,
                        datetime.min.time()
                    ).replace(tzinfo=timezone.utc)
                else:
                    checkpoints[timeframe] = None

            # –ó–∞–ø–æ–ª–Ω—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã
            for tf in self.timeframes:
                if tf not in checkpoints:
                    checkpoints[tf] = None

            return checkpoints

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ checkpoints: {e}")
            return {tf: None for tf in self.timeframes}
        finally:
            cursor.close()
            conn.close()

    def get_checkpoint(self, timeframe: str) -> Optional[datetime]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ checkpoint –¥–ª—è —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞

        DEPRECATED: –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å get_all_checkpoints() –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

        Args:
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º (1m, 15m, 1h)

        Returns:
            –ü–æ—Å–ª–µ–¥–Ω—è—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –¥–∞—Ç–∞ –∏–ª–∏ None
        """
        # –ï—Å–ª–∏ –µ—Å—Ç—å –∫–µ—à - –±–µ—Ä–µ–º –æ—Ç—Ç—É–¥–∞
        if self.checkpoints_cache and timeframe in self.checkpoints_cache:
            return self.checkpoints_cache[timeframe]

        conn = self.connect_db()
        cursor = conn.cursor()

        try:
            table_name = f'indicators_bybit_futures_{timeframe}'

            # –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–û: DATE(MAX()) –≤–º–µ—Å—Ç–æ MAX(DATE()) - –Ω–∞–º–Ω–æ–≥–æ –±—ã—Å—Ç—Ä–µ–µ!
            # DATE() –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ 1 —Ä–∞–∑ –≤–º–µ—Å—Ç–æ –≤—ã–∑–æ–≤–∞ –Ω–∞ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–µ
            cursor.execute(f"""
                SELECT DATE(MAX(timestamp))
                FROM {table_name}
                WHERE symbol = %s
                  AND {self.index_column} IS NOT NULL
            """, (self.symbol,))

            result = cursor.fetchone()
            if result and result[0]:
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ datetime —Å –≤—Ä–µ–º–µ–Ω–µ–º 00:00:00
                return datetime.combine(result[0], datetime.min.time()).replace(tzinfo=timezone.utc)
            return None

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ checkpoint: {e}")
            return None
        finally:
            cursor.close()
            conn.close()

    def update_batch(self, timeframe: str, date: date, value: int, classification: str, conn=None) -> int:
        """
        –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö Fear & Greed –¥–ª—è –æ–¥–Ω–æ–≥–æ –¥–Ω—è

        Args:
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º
            date: –î–∞—Ç–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
            value: –ó–Ω–∞—á–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
            classification: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
            conn: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ DB —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ (–¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏)

        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
        """
        # –ï—Å–ª–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω–æ - —Å–æ–∑–¥–∞–µ–º —Å–≤–æ–µ (–æ–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å)
        own_connection = False
        if conn is None:
            conn = self.connect_db()
            own_connection = True

        cursor = conn.cursor()

        try:
            table_name = f'indicators_bybit_futures_{timeframe}'

            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –¥–ª—è –Ω–∞—á–∞–ª–∞ –∏ –∫–æ–Ω—Ü–∞ –¥–Ω—è (UTC)
            start_ts = datetime.combine(date, datetime.min.time()).replace(tzinfo=timezone.utc)
            end_ts = start_ts + timedelta(days=1)

            # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Å–µ –∑–∞–ø–∏—Å–∏ –∑–∞ –¥–µ–Ω—å –∏—Å–ø–æ–ª—å–∑—É—è BETWEEN –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞
            cursor.execute(f"""
                UPDATE {table_name}
                SET
                    {self.index_column} = %s,
                    {self.classification_column} = %s
                WHERE symbol = %s
                  AND timestamp >= %s
                  AND timestamp < %s
                  AND {self.index_column} IS NULL
            """, (value, classification, self.symbol, start_ts, end_ts))

            updated_count = cursor.rowcount

            # –ö–æ–º–º–∏—Ç–∏–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –º—ã —Å–æ–∑–¥–∞–ª–∏ —Å–≤–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
            if own_connection:
                conn.commit()

            return updated_count

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            if own_connection:
                conn.rollback()
            return 0
        finally:
            cursor.close()
            # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –º—ã —Å–æ–∑–¥–∞–ª–∏ —Å–≤–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
            if own_connection:
                conn.close()

    def validate_day_consistency(self, date: date) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö –∑–∞ –¥–µ–Ω—å –º–µ–∂–¥—É —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º–∏

        Args:
            date: –î–∞—Ç–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏

        Returns:
            True –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã
        """
        conn = self.connect_db()
        cursor = conn.cursor()

        try:
            values = {}

            for timeframe in self.timeframes:
                table_name = f'indicators_bybit_futures_{timeframe}'

                cursor.execute(f"""
                    SELECT DISTINCT {self.index_column}, {self.classification_column}
                    FROM {table_name}
                    WHERE symbol = %s
                      AND DATE(timestamp) = %s
                      AND {self.index_column} IS NOT NULL
                """, (self.symbol, date))

                results = cursor.fetchall()
                if results:
                    if len(results) > 1:
                        self.logger.warning(f"  ‚ö†Ô∏è –ù–µ—Å–∫–æ–ª—å–∫–æ –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è {timeframe}: {results}")
                        return False
                    values[timeframe] = results[0]

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ
            unique_values = set(values.values())
            if len(unique_values) > 1:
                self.logger.warning(f"  ‚ö†Ô∏è –†–∞–∑–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ–∂–¥—É —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º–∏: {values}")
                return False

            return True

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏: {e}")
            return False
        finally:
            cursor.close()
            conn.close()

    def process_timeframe(self, timeframe: str, start_date: datetime, end_date: datetime) -> bool:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞

        Args:
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º
            start_date: –ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞
            end_date: –ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞

        Returns:
            True –µ—Å–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —É—Å–ø–µ—à–Ω–∞
        """
        self.logger.info(f"\nüìä –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞: {timeframe}")
        self.logger.info(f"üìÖ –ü–µ—Ä–∏–æ–¥: {start_date.date()} - {end_date.date()}")

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π checkpoint (–Ω–µ –¥–µ–ª–∞–µ–º –Ω–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –∫ –ë–î!)
        checkpoint = self.checkpoints_cache.get(timeframe) if self.checkpoints_cache else None
        if checkpoint and checkpoint >= start_date:
            self.logger.info(f"‚è© –ü—Ä–æ–¥–æ–ª–∂–∞—é —Å checkpoint: {checkpoint.date()}")
            current_date = checkpoint + timedelta(days=1)
        else:
            current_date = start_date

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        total_days = (end_date - current_date).days + 1
        if total_days <= 0:
            self.logger.info("‚úÖ –ù–µ—Ç –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return True

        self.logger.info(f"üì¶ –î–Ω–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {total_days}")

        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ API –µ—Å–ª–∏ –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã
        api_data = self.api_data_cache or self.get_api_data()
        if not api_data:
            self.logger.error("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö API –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return False

        # –û—Ç–∫—Ä—ã–≤–∞–µ–º –û–î–ù–û —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–ª—è –≤—Å–µ—Ö –¥–Ω–µ–π (–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è)
        conn = self.connect_db()

        try:
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ –¥–Ω—è–º —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º
            processed_days = 0
            updated_records = 0
            commit_batch_size = 10  # –ö–æ–º–º–∏—Ç–∏–º –∫–∞–∂–¥—ã–µ 10 –¥–Ω–µ–π

            with tqdm(total=total_days, desc=f"{timeframe}", unit="–¥–µ–Ω—å") as pbar:
                while current_date <= end_date:
                    date_key = current_date.date()

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –¥–∞–Ω–Ω—ã–µ –∑–∞ —ç—Ç–æ—Ç –¥–µ–Ω—å
                    if date_key in api_data:
                        data = api_data[date_key]
                        value = data['value']
                        classification = data['classification']

                        # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ (–ø–µ—Ä–µ–¥–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ)
                        count = self.update_batch(timeframe, date_key, value, classification, conn=conn)
                        updated_records += count

                        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
                        pbar.set_description(f"{timeframe}: {date_key} (CMC={value}, –æ–±–Ω–æ–≤–ª–µ–Ω–æ={count})")
                        processed_days += 1

                        # Batch commit –∫–∞–∂–¥—ã–µ N –¥–Ω–µ–π
                        if processed_days % commit_batch_size == 0:
                            conn.commit()
                            self.logger.debug(f"  üíæ Commit –ø–æ—Å–ª–µ {processed_days} –¥–Ω–µ–π")
                    else:
                        # –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∑–∞ —ç—Ç–æ—Ç –¥–µ–Ω—å
                        pbar.set_description(f"{timeframe}: {date_key} (–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö API)")
                        self.logger.debug(f"  ‚è© –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö API –¥–ª—è {date_key}, –ø—Ä–æ–ø—É—Å–∫–∞—é")

                    current_date += timedelta(days=1)
                    pbar.update(1)

            # –§–∏–Ω–∞–ª—å–Ω—ã–π commit
            conn.commit()
            self.logger.debug(f"  üíæ –§–∏–Ω–∞–ª—å–Ω—ã–π commit")

            self.logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_days} –¥–Ω–µ–π, –æ–±–Ω–æ–≤–ª–µ–Ω–æ {updated_records} –∑–∞–ø–∏—Å–µ–π")
            return True

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞: {e}")
            conn.rollback()
            return False
        finally:
            conn.close()

    def run(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∑–∞–ø—É—Å–∫–∞ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞"""
        try:
            # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
            if not self.create_columns():
                self.logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∫–æ–ª–æ–Ω–∫–∏")
                return False

            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å API
            api_data = self.get_api_data()
            if not api_data:
                self.logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Å API")
                return False

            # –ü–æ–ª—É—á–∞–µ–º checkpoint'—ã –¥–ª—è –í–°–ï–• —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ –û–î–ù–ò–ú –∑–∞–ø—Ä–æ—Å–æ–º (–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è)
            self.logger.info("üìç –ü–æ–ª—É—á–µ–Ω–∏–µ checkpoint'–æ–≤ –¥–ª—è –≤—Å–µ—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤...")
            self.checkpoints_cache = self.get_all_checkpoints()
            for tf in self.timeframes:
                checkpoint_info = self.checkpoints_cache.get(tf)
                if checkpoint_info:
                    self.logger.info(f"   ‚Ä¢ {tf}: {checkpoint_info.date()}")
                else:
                    self.logger.info(f"   ‚Ä¢ {tf}: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö")

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–µ—Ä–∏–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            conn = self.connect_db()
            cursor = conn.cursor()

            # –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–û: DATE(MIN/MAX()) –≤–º–µ—Å—Ç–æ MIN/MAX(DATE()) - –Ω–∞–º–Ω–æ–≥–æ –±—ã—Å—Ç—Ä–µ–µ!
            # DATE() –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ 2 —Ä–∞–∑–∞ –≤–º–µ—Å—Ç–æ –≤—ã–∑–æ–≤–∞ –Ω–∞ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–µ
            cursor.execute("""
                SELECT
                    DATE(MIN(timestamp)) as min_date,
                    DATE(MAX(timestamp)) as max_date
                FROM indicators_bybit_futures_1m
                WHERE symbol = %s
            """, (self.symbol,))

            result = cursor.fetchone()
            cursor.close()
            conn.close()

            if not result or not result[0]:
                self.logger.error("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ –ë–î –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                return False

            db_min_date = result[0]
            db_max_date = result[1]

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∞—Ç—ã –∏–∑ API –¥–∞–Ω–Ω—ã—Ö
            api_dates = sorted(api_data.keys())
            api_min_date = api_dates[0]
            api_max_date = api_dates[-1]

            # –ù–∞—á–∏–Ω–∞–µ–º —Å –º–∞–∫—Å–∏–º—É–º–∞ –º–µ–∂–¥—É –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –¥–∞—Ç–æ–π –ë–î –∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –¥–∞—Ç–æ–π API
            start_date = max(db_min_date, api_min_date)
            # –ó–∞–∫–∞–Ω—á–∏–≤–∞–µ–º –º–∏–Ω–∏–º—É–º–æ–º –º–µ–∂–¥—É –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–∞—Ç–æ–π –ë–î –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–∞—Ç–æ–π API
            end_date = min(db_max_date, api_max_date)

            self.logger.info(f"\nüìÖ –û–±—â–∏–π –ø–µ—Ä–∏–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
            self.logger.info(f"   –ë–î: {db_min_date} - {db_max_date}")
            self.logger.info(f"   API: {api_min_date} - {api_max_date}")
            self.logger.info(f"   –û–±—Ä–∞–±–æ—Ç–∫–∞: {start_date} - {end_date}")

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ datetime
            start_datetime = datetime.combine(start_date, datetime.min.time()).replace(tzinfo=timezone.utc)
            end_datetime = datetime.combine(end_date, datetime.min.time()).replace(tzinfo=timezone.utc)

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Ç–∞–π–º—Ñ—Ä–µ–π–º
            for timeframe in self.timeframes:
                if not self.process_timeframe(timeframe, start_datetime, end_datetime):
                    self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ {timeframe}")
                    return False

            self.logger.info("\n" + "=" * 60)
            self.logger.info("‚úÖ CoinMarketCap Fear & Greed Index —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")
            self.logger.info("=" * 60)
            return True

        except KeyboardInterrupt:
            self.logger.info("\n‚ö†Ô∏è –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º. –ú–æ–∂–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –ø–æ–∑–∂–µ —Å —ç—Ç–æ–≥–æ –º–µ—Å—Ç–∞.")
            sys.exit(0)
        except Exception as e:
            self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
            return False


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    loader = CoinMarketCapFearGreedLoader()
    success = loader.run()
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()