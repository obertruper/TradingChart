#!/usr/bin/env python3
"""
CoinMarketCap Fear & Greed Index Loader
–ó–∞–≥—Ä—É–∑—á–∏–∫ –∏–Ω–¥–µ–∫—Å–∞ —Å—Ç—Ä–∞—Ö–∞ –∏ –∂–∞–¥–Ω–æ—Å—Ç–∏ –æ—Ç CoinMarketCap –¥–ª—è –≤—Å–µ—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
"""

import os
import sys
import psycopg2
from psycopg2.extras import RealDictCursor
import yaml
import logging
from datetime import datetime, timezone, timedelta, date
from typing import Optional, Dict, List, Tuple
import requests
import json
from tqdm import tqdm
import time

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


class CoinMarketCapFearGreedLoader:
    """–ó–∞–≥—Ä—É–∑—á–∏–∫ Fear & Greed Index –æ—Ç CoinMarketCap"""

    def __init__(self, config_path: str = 'indicators_config.yaml'):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≥—Ä—É–∑—á–∏–∫–∞

        Args:
            config_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        """
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        self.config_path = config_path
        self.load_config()

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        self.setup_logging()

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î
        self.db_config = self.config['database']

        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è CoinMarketCap API
        self.api_config = self.config.get('indicators', {}).get('coinmarketcap_fear_and_greed', {})
        self.api_key = self.api_config.get('api_key')
        self.base_url = self.api_config.get('base_url', 'https://pro-api.coinmarketcap.com')
        self.batch_size = self.api_config.get('batch_size', 500)
        self.batch_days = self.api_config.get('batch_days', 1)
        self.retry_on_error = self.api_config.get('retry_on_error', 3)

        # –°–∏–º–≤–æ–ª –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (Fear & Greed –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –∫ BTCUSDT)
        self.symbol = 'BTCUSDT'

        # –¢–∞–π–º—Ñ—Ä–µ–π–º—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.timeframes = self.api_config.get('timeframes', ['1m', '15m', '1h'])

        # –ù–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ –≤ –ë–î
        self.index_column = 'fear_and_greed_index_coinmarketcap'
        self.classification_column = 'fear_and_greed_index_coinmarketcap_classification'

        # –ö–µ—à –¥–ª—è API –¥–∞–Ω–Ω—ã—Ö
        self.api_data_cache = None

        self.logger.info("=" * 60)
        self.logger.info("üöÄ –ó–∞–ø—É—Å–∫ CoinMarketCap Fear & Greed Index Loader")
        self.logger.info(f"üéØ –°–∏–º–≤–æ–ª: {self.symbol}")
        self.logger.info(f"‚è±Ô∏è –¢–∞–π–º—Ñ—Ä–µ–π–º—ã: {', '.join(self.timeframes)}")
        self.logger.info("=" * 60)

    def load_config(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ —Ñ–∞–π–ª–∞"""
        config_dir = os.path.dirname(os.path.abspath(__file__))
        config_file = os.path.join(config_dir, self.config_path)

        if not os.path.exists(config_file):
            raise FileNotFoundError(f"–§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {config_file}")

        with open(config_file, 'r') as f:
            self.config = yaml.safe_load(f)

    def setup_logging(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –ª–æ–≥–æ–≤ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        log_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'logs')
        os.makedirs(log_dir, exist_ok=True)

        # –ò–º—è —Ñ–∞–π–ª–∞ –ª–æ–≥–∞ —Å —Ç–µ–∫—É—â–µ–π –¥–∞—Ç–æ–π –∏ –≤—Ä–µ–º–µ–Ω–µ–º
        log_filename = os.path.join(
            log_dir,
            f"coinmarketcap_fear_greed_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        )

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_filename, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )

        self.logger = logging.getLogger(__name__)
        self.logger.info(f"üìù CoinMarketCap Fear & Greed Loader: –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ. –õ–æ–≥-—Ñ–∞–π–ª: {log_filename}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ø–æ—Å–ª–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        config_file = os.path.join(os.path.dirname(os.path.abspath(__file__)), self.config_path)
        self.logger.info(f"üìã –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {config_file}")

    def connect_db(self):
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            conn = psycopg2.connect(
                host=self.db_config['host'],
                port=self.db_config['port'],
                database=self.db_config['database'],
                user=self.db_config['user'],
                password=self.db_config['password']
            )
            return conn
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î: {e}")
            raise

    def create_columns(self) -> bool:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è Fear & Greed Index –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç

        Returns:
            bool: True –µ—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∏ —Å–æ–∑–¥–∞–Ω—ã –∏–ª–∏ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
        """
        self.logger.info("üî® –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ CoinMarketCap Fear & Greed...")

        conn = self.connect_db()
        cursor = conn.cursor()

        try:
            for timeframe in self.timeframes:
                table_name = f'indicators_bybit_futures_{timeframe}'

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã
                cursor.execute("""
                    SELECT EXISTS (
                        SELECT FROM information_schema.tables
                        WHERE table_name = %s
                    )
                """, (table_name,))

                if not cursor.fetchone()[0]:
                    self.logger.error(f"  ‚ùå –¢–∞–±–ª–∏—Ü–∞ {table_name} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
                    return False

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ —Å–æ–∑–¥–∞–µ–º –∫–æ–ª–æ–Ω–∫—É –¥–ª—è –∑–Ω–∞—á–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞
                cursor.execute(f"""
                    SELECT column_name
                    FROM information_schema.columns
                    WHERE table_name = %s AND column_name = %s
                """, (table_name, self.index_column))

                if not cursor.fetchone():
                    cursor.execute(f"""
                        ALTER TABLE {table_name}
                        ADD COLUMN {self.index_column} SMALLINT
                    """)
                    conn.commit()
                    self.logger.info(f"  ‚úÖ –ö–æ–ª–æ–Ω–∫–∞ {self.index_column} —Å–æ–∑–¥–∞–Ω–∞ –≤ {table_name}")
                else:
                    self.logger.info(f"  ‚úÖ –ö–æ–ª–æ–Ω–∫–∞ {self.index_column} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ {table_name}")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ —Å–æ–∑–¥–∞–µ–º –∫–æ–ª–æ–Ω–∫—É –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
                cursor.execute(f"""
                    SELECT column_name
                    FROM information_schema.columns
                    WHERE table_name = %s AND column_name = %s
                """, (table_name, self.classification_column))

                if not cursor.fetchone():
                    cursor.execute(f"""
                        ALTER TABLE {table_name}
                        ADD COLUMN {self.classification_column} VARCHAR(20)
                    """)
                    conn.commit()
                    self.logger.info(f"  ‚úÖ –ö–æ–ª–æ–Ω–∫–∞ {self.classification_column} —Å–æ–∑–¥–∞–Ω–∞ –≤ {table_name}")
                else:
                    self.logger.info(f"  ‚úÖ –ö–æ–ª–æ–Ω–∫–∞ {self.classification_column} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ {table_name}")

            self.logger.info("‚úÖ –í—Å–µ –∫–æ–ª–æ–Ω–∫–∏ –≥–æ—Ç–æ–≤—ã")
            return True

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∫–æ–ª–æ–Ω–æ–∫: {e}")
            conn.rollback()
            return False
        finally:
            cursor.close()
            conn.close()

    def get_api_data(self) -> Optional[Dict]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å API CoinMarketCap

        Returns:
            Dict —Å –¥–∞–Ω–Ω—ã–º–∏ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        if self.api_data_cache:
            self.logger.info("üì¶ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ API")
            return self.api_data_cache

        self.logger.info(f"üì° –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å CoinMarketCap API")

        if not self.api_key:
            self.logger.error("‚ùå API –∫–ª—é—á –Ω–µ —É–∫–∞–∑–∞–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
            return None

        headers = {
            'X-CMC_PRO_API_KEY': self.api_key,
            'Accept': 'application/json'
        }

        all_data = []
        total_credits_used = 0

        try:
            # –ü–µ—Ä–≤—ã–π –±–∞—Ç—á - –ø–æ—Å–ª–µ–¥–Ω–∏–µ 500 –∑–∞–ø–∏—Å–µ–π
            url = f'{self.base_url}/v3/fear-and-greed/historical'
            params = {'limit': self.batch_size}

            self.logger.info(f"  üì• –ó–∞–ø—Ä–æ—Å –±–∞—Ç—á–∞ 1 (limit={self.batch_size})...")
            response = requests.get(url, headers=headers, params=params, timeout=30)

            if response.status_code == 200:
                data = response.json()
                status = data.get('status', {})
                credits = status.get('credit_count', 0)
                total_credits_used += credits

                if 'data' in data and data['data']:
                    batch1 = data['data']
                    all_data.extend(batch1)
                    self.logger.info(f"  ‚úÖ –ë–∞—Ç—á 1: –ø–æ–ª—É—á–µ–Ω–æ {len(batch1)} –∑–∞–ø–∏—Å–µ–π (–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ {credits} –∫—Ä–µ–¥–∏—Ç–æ–≤)")
            else:
                self.logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ API (–±–∞—Ç—á 1): {response.status_code}")
                if response.status_code == 429:
                    self.logger.error("  ‚ö†Ô∏è –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ API")
                elif response.status_code == 401:
                    self.logger.error("  ‚ö†Ô∏è –ù–µ–≤–µ—Ä–Ω—ã–π API –∫–ª—é—á")
                return None

            # –í—Ç–æ—Ä–æ–π –±–∞—Ç—á - —Å–ª–µ–¥—É—é—â–∏–µ –∑–∞–ø–∏—Å–∏
            params = {'start': 500, 'limit': self.batch_size}
            self.logger.info(f"  üì• –ó–∞–ø—Ä–æ—Å –±–∞—Ç—á–∞ 2 (start=500, limit={self.batch_size})...")
            response = requests.get(url, headers=headers, params=params, timeout=30)

            if response.status_code == 200:
                data = response.json()
                status = data.get('status', {})
                credits = status.get('credit_count', 0)
                total_credits_used += credits

                if 'data' in data and data['data']:
                    batch2 = data['data']
                    all_data.extend(batch2)
                    self.logger.info(f"  ‚úÖ –ë–∞—Ç—á 2: –ø–æ–ª—É—á–µ–Ω–æ {len(batch2)} –∑–∞–ø–∏—Å–µ–π (–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ {credits} –∫—Ä–µ–¥–∏—Ç–æ–≤)")
            else:
                self.logger.warning(f"  ‚ö†Ô∏è –ë–∞—Ç—á 2: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –æ—à–∏–±–∫–∞ {response.status_code}")

            if all_data:
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Å–ª–æ–≤–∞—Ä—å –ø–æ –¥–∞—Ç–∞–º
                data_by_date = {}

                for record in all_data:
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º timestamp –≤ –¥–∞—Ç—É
                    ts = int(record['timestamp'])
                    dt = datetime.fromtimestamp(ts, tz=timezone.utc)
                    date_key = dt.date()

                    data_by_date[date_key] = {
                        'value': record['value'],
                        'classification': record['value_classification']
                    }

                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–∞–º
                sorted_dates = sorted(data_by_date.keys())

                self.logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data_by_date)} –¥–Ω–µ–π –¥–∞–Ω–Ω—ã—Ö")
                self.logger.info(f"üìÖ –ü–µ—Ä–∏–æ–¥: {sorted_dates[0]} - {sorted_dates[-1]}")
                self.logger.info(f"üí≥ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –∫—Ä–µ–¥–∏—Ç–æ–≤: {total_credits_used}")

                # –ö–µ—à–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
                self.api_data_cache = data_by_date
                return data_by_date
            else:
                self.logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Å API")
                return None

        except requests.exceptions.RequestException as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ API: {e}")
            return None
        except Exception as e:
            self.logger.error(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
            return None

    def get_checkpoint(self, timeframe: str) -> Optional[datetime]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ checkpoint –¥–ª—è —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞

        Args:
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º (1m, 15m, 1h)

        Returns:
            –ü–æ—Å–ª–µ–¥–Ω—è—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –¥–∞—Ç–∞ –∏–ª–∏ None
        """
        conn = self.connect_db()
        cursor = conn.cursor()

        try:
            table_name = f'indicators_bybit_futures_{timeframe}'

            # –ü–æ–ª—É—á–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–∞—Ç—É —Å –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–º CoinMarketCap Fear & Greed
            cursor.execute(f"""
                SELECT MAX(DATE(timestamp))
                FROM {table_name}
                WHERE symbol = %s
                  AND {self.index_column} IS NOT NULL
            """, (self.symbol,))

            result = cursor.fetchone()
            if result and result[0]:
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ datetime —Å –≤—Ä–µ–º–µ–Ω–µ–º 00:00:00
                return datetime.combine(result[0], datetime.min.time()).replace(tzinfo=timezone.utc)
            return None

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ checkpoint: {e}")
            return None
        finally:
            cursor.close()
            conn.close()

    def update_batch(self, timeframe: str, date: date, value: int, classification: str) -> int:
        """
        –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö Fear & Greed –¥–ª—è –æ–¥–Ω–æ–≥–æ –¥–Ω—è

        Args:
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º
            date: –î–∞—Ç–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
            value: –ó–Ω–∞—á–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
            classification: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è

        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
        """
        conn = self.connect_db()
        cursor = conn.cursor()

        try:
            table_name = f'indicators_bybit_futures_{timeframe}'

            # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Å–µ –∑–∞–ø–∏—Å–∏ –∑–∞ –¥–µ–Ω—å
            cursor.execute(f"""
                UPDATE {table_name}
                SET
                    {self.index_column} = %s,
                    {self.classification_column} = %s
                WHERE symbol = %s
                  AND DATE(timestamp) = %s
                  AND {self.index_column} IS NULL
            """, (value, classification, self.symbol, date))

            updated_count = cursor.rowcount
            conn.commit()

            return updated_count

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            conn.rollback()
            return 0
        finally:
            cursor.close()
            conn.close()

    def validate_day_consistency(self, date: date) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö –∑–∞ –¥–µ–Ω—å –º–µ–∂–¥—É —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º–∏

        Args:
            date: –î–∞—Ç–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏

        Returns:
            True –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã
        """
        conn = self.connect_db()
        cursor = conn.cursor()

        try:
            values = {}

            for timeframe in self.timeframes:
                table_name = f'indicators_bybit_futures_{timeframe}'

                cursor.execute(f"""
                    SELECT DISTINCT {self.index_column}, {self.classification_column}
                    FROM {table_name}
                    WHERE symbol = %s
                      AND DATE(timestamp) = %s
                      AND {self.index_column} IS NOT NULL
                """, (self.symbol, date))

                results = cursor.fetchall()
                if results:
                    if len(results) > 1:
                        self.logger.warning(f"  ‚ö†Ô∏è –ù–µ—Å–∫–æ–ª—å–∫–æ –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è {timeframe}: {results}")
                        return False
                    values[timeframe] = results[0]

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ
            unique_values = set(values.values())
            if len(unique_values) > 1:
                self.logger.warning(f"  ‚ö†Ô∏è –†–∞–∑–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ–∂–¥—É —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º–∏: {values}")
                return False

            return True

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏: {e}")
            return False
        finally:
            cursor.close()
            conn.close()

    def process_timeframe(self, timeframe: str, start_date: datetime, end_date: datetime) -> bool:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞

        Args:
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º
            start_date: –ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞
            end_date: –ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞

        Returns:
            True –µ—Å–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —É—Å–ø–µ—à–Ω–∞
        """
        self.logger.info(f"\nüìä –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞: {timeframe}")
        self.logger.info(f"üìÖ –ü–µ—Ä–∏–æ–¥: {start_date.date()} - {end_date.date()}")

        # –ü–æ–ª—É—á–∞–µ–º checkpoint
        checkpoint = self.get_checkpoint(timeframe)
        if checkpoint and checkpoint >= start_date:
            self.logger.info(f"‚è© –ü—Ä–æ–¥–æ–ª–∂–∞—é —Å checkpoint: {checkpoint.date()}")
            current_date = checkpoint + timedelta(days=1)
        else:
            current_date = start_date

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        total_days = (end_date - current_date).days + 1
        if total_days <= 0:
            self.logger.info("‚úÖ –ù–µ—Ç –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return True

        self.logger.info(f"üì¶ –î–Ω–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {total_days}")

        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ API –µ—Å–ª–∏ –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã
        api_data = self.api_data_cache or self.get_api_data()
        if not api_data:
            self.logger.error("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö API –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return False

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ –¥–Ω—è–º —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º
        processed_days = 0
        updated_records = 0

        with tqdm(total=total_days, desc=f"{timeframe}", unit="–¥–µ–Ω—å") as pbar:
            while current_date <= end_date:
                date_key = current_date.date()

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –¥–∞–Ω–Ω—ã–µ –∑–∞ —ç—Ç–æ—Ç –¥–µ–Ω—å
                if date_key in api_data:
                    data = api_data[date_key]
                    value = data['value']
                    classification = data['classification']

                    # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
                    count = self.update_batch(timeframe, date_key, value, classification)
                    updated_records += count

                    # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
                    pbar.set_description(f"{timeframe}: {date_key} (CMC={value}, –æ–±–Ω–æ–≤–ª–µ–Ω–æ={count})")
                    processed_days += 1
                else:
                    # –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∑–∞ —ç—Ç–æ—Ç –¥–µ–Ω—å
                    pbar.set_description(f"{timeframe}: {date_key} (–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö API)")
                    self.logger.debug(f"  ‚è© –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö API –¥–ª—è {date_key}, –ø—Ä–æ–ø—É—Å–∫–∞—é")

                current_date += timedelta(days=1)
                pbar.update(1)

        self.logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_days} –¥–Ω–µ–π, –æ–±–Ω–æ–≤–ª–µ–Ω–æ {updated_records} –∑–∞–ø–∏—Å–µ–π")
        return True

    def run(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∑–∞–ø—É—Å–∫–∞ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞"""
        try:
            # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
            if not self.create_columns():
                self.logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∫–æ–ª–æ–Ω–∫–∏")
                return False

            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å API
            api_data = self.get_api_data()
            if not api_data:
                self.logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Å API")
                return False

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–µ—Ä–∏–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            conn = self.connect_db()
            cursor = conn.cursor()

            # –ü–æ–ª—É—á–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–∞—Ç—ã –∏–∑ –ë–î
            cursor.execute("""
                SELECT
                    MIN(DATE(timestamp)) as min_date,
                    MAX(DATE(timestamp)) as max_date
                FROM indicators_bybit_futures_1m
                WHERE symbol = %s
            """, (self.symbol,))

            result = cursor.fetchone()
            cursor.close()
            conn.close()

            if not result or not result[0]:
                self.logger.error("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ –ë–î –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                return False

            db_min_date = result[0]
            db_max_date = result[1]

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∞—Ç—ã –∏–∑ API –¥–∞–Ω–Ω—ã—Ö
            api_dates = sorted(api_data.keys())
            api_min_date = api_dates[0]
            api_max_date = api_dates[-1]

            # –ù–∞—á–∏–Ω–∞–µ–º —Å –º–∞–∫—Å–∏–º—É–º–∞ –º–µ–∂–¥—É –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –¥–∞—Ç–æ–π –ë–î –∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –¥–∞—Ç–æ–π API
            start_date = max(db_min_date, api_min_date)
            # –ó–∞–∫–∞–Ω—á–∏–≤–∞–µ–º –º–∏–Ω–∏–º—É–º–æ–º –º–µ–∂–¥—É –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–∞—Ç–æ–π –ë–î –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–∞—Ç–æ–π API
            end_date = min(db_max_date, api_max_date)

            self.logger.info(f"\nüìÖ –û–±—â–∏–π –ø–µ—Ä–∏–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
            self.logger.info(f"   –ë–î: {db_min_date} - {db_max_date}")
            self.logger.info(f"   API: {api_min_date} - {api_max_date}")
            self.logger.info(f"   –û–±—Ä–∞–±–æ—Ç–∫–∞: {start_date} - {end_date}")

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ datetime
            start_datetime = datetime.combine(start_date, datetime.min.time()).replace(tzinfo=timezone.utc)
            end_datetime = datetime.combine(end_date, datetime.min.time()).replace(tzinfo=timezone.utc)

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Ç–∞–π–º—Ñ—Ä–µ–π–º
            for timeframe in self.timeframes:
                if not self.process_timeframe(timeframe, start_datetime, end_datetime):
                    self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ {timeframe}")
                    return False

            self.logger.info("\n" + "=" * 60)
            self.logger.info("‚úÖ CoinMarketCap Fear & Greed Index —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")
            self.logger.info("=" * 60)
            return True

        except Exception as e:
            self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
            return False


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    loader = CoinMarketCapFearGreedLoader()
    success = loader.run()
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()